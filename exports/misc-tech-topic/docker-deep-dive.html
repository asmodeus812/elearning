<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>docker-deep-dive</title>
  <style>
    html {
      font-size: 12pt;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  \usepackage{listings}
  \usepackage{xcolor}

  \lstset{
      basicstyle=\ttfamily,
      backgroundcolor=\color{black!10},
      showspaces=false,
      showstringspaces=false,
      showtabs=false,
      tabsize=2,
      captionpos=b,
      breaklines=true,
      breakautoindent=true,
      linewidth=\textwidth
  }
</head>
<body>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a>
<ul>
<li><a href="#vmware" id="toc-vmware">VMware</a></li>
<li><a href="#containers" id="toc-containers">Containers</a>
<ul>
<li><a href="#linux-containers" id="toc-linux-containers">Linux
containers</a></li>
<li><a href="#windows-containers" id="toc-windows-containers">Windows
containers</a></li>
<li><a href="#mac-containers" id="toc-mac-containers">Mac
containers</a></li>
<li><a href="#windows-vs-linux-containers"
id="toc-windows-vs-linux-containers">Windows vs Linux
containers</a></li>
</ul></li>
</ul></li>
<li><a href="#docker" id="toc-docker">Docker</a>
<ul>
<li><a href="#docker-inc" id="toc-docker-inc">Docker, Inc</a></li>
<li><a href="#docker-runtime-and-orchestration"
id="toc-docker-runtime-and-orchestration">Docker runtime and
orchestration</a></li>
<li><a href="#docker-project---moby"
id="toc-docker-project---moby">Docker project - MOBY</a></li>
<li><a href="#container-ecosystem"
id="toc-container-ecosystem">Container ecosystem</a></li>
<li><a href="#open-container-initiative"
id="toc-open-container-initiative">Open container initiative</a></li>
<li><a href="#kernel" id="toc-kernel">Kernel</a>
<ul>
<li><a href="#control-groups-cgroups"
id="toc-control-groups-cgroups">Control groups (cgroups)</a></li>
<li><a href="#namespaces-namespaces"
id="toc-namespaces-namespaces">Namespaces (namespaces)</a></li>
<li><a href="#cgroup-namespaces" id="toc-cgroup-namespaces">Cgroup &amp;
Namespaces</a></li>
</ul></li>
<li><a href="#containerization"
id="toc-containerization">Containerization</a></li>
<li><a href="#more-kernel-components"
id="toc-more-kernel-components">More kernel components</a>
<ul>
<li><a href="#overlayfs" id="toc-overlayfs">OverlayFS</a></li>
<li><a href="#seccomp" id="toc-seccomp">Seccomp</a></li>
<li><a href="#capabilities" id="toc-capabilities">Capabilities</a></li>
<li><a href="#apparmor-selinux" id="toc-apparmor-selinux">AppArmor &amp;
SELinux</a></li>
<li><a href="#capabilities-nnp" id="toc-capabilities-nnp">Capabilities
&amp; NNP</a></li>
<li><a href="#device-control" id="toc-device-control">Device
control</a></li>
<li><a href="#network-virtualization"
id="toc-network-virtualization">Network virtualization</a></li>
<li><a href="#resource-limits" id="toc-resource-limits">Resource
limits</a></li>
</ul></li>
</ul></li>
<li><a href="#components" id="toc-components">Components</a>
<ul>
<li><a href="#images" id="toc-images">Images</a></li>
<li><a href="#containers-1" id="toc-containers-1">Containers</a>
<ul>
<li><a href="#attaching" id="toc-attaching">Attaching</a></li>
<li><a href="#stopping" id="toc-stopping">Stopping</a></li>
<li><a href="#removing" id="toc-removing">Removing</a></li>
</ul></li>
<li><a href="#dockerfile" id="toc-dockerfile">Dockerfile</a></li>
<li><a href="#docker-engine" id="toc-docker-engine">Docker
engine</a></li>
</ul></li>
<li><a href="#deep-dive" id="toc-deep-dive">Deep-dive</a>
<ul>
<li><a href="#images-1" id="toc-images-1">Images</a>
<ul>
<li><a href="#definition" id="toc-definition">Definition</a></li>
<li><a href="#pulling" id="toc-pulling">Pulling</a></li>
<li><a href="#names" id="toc-names">Names</a></li>
<li><a href="#tags" id="toc-tags">Tags</a></li>
<li><a href="#layers" id="toc-layers">Layers</a></li>
<li><a href="#digest" id="toc-digest">Digest</a></li>
<li><a href="#architecture" id="toc-architecture">Architecture</a></li>
<li><a href="#deleting" id="toc-deleting">Deleting</a></li>
</ul></li>
<li><a href="#containers-2" id="toc-containers-2">Containers</a>
<ul>
<li><a href="#definition-1" id="toc-definition-1">Definition</a></li>
</ul></li>
<li><a href="#containerizing-application"
id="toc-containerizing-application">Containerizing application</a></li>
<li><a href="#definition-2" id="toc-definition-2">Definition</a>
<ul>
<li><a href="#getting-the-code" id="toc-getting-the-code">Getting the
code</a></li>
<li><a href="#building-the-docker-file"
id="toc-building-the-docker-file">Building the docker file</a></li>
<li><a href="#containerize-the-app-and-build-the-image"
id="toc-containerize-the-app-and-build-the-image">Containerize the app
and build the image</a></li>
<li><a href="#running-the-app" id="toc-running-the-app">Running the
app</a></li>
<li><a href="#test-connectivity" id="toc-test-connectivity">Test
connectivity</a></li>
</ul></li>
<li><a href="#closer-look" id="toc-closer-look">Closer look</a></li>
<li><a href="#moving-to-production" id="toc-moving-to-production">Moving
to production</a></li>
</ul></li>
<li><a href="#swarm-mode" id="toc-swarm-mode">Swarm mode</a>
<ul>
<li><a href="#definition-3" id="toc-definition-3">Definition</a></li>
<li><a href="#swarm" id="toc-swarm">Swarm</a>
<ul>
<li><a href="#tasks" id="toc-tasks">Tasks</a></li>
<li><a href="#enabling" id="toc-enabling">Enabling</a></li>
<li><a href="#service" id="toc-service">Service</a></li>
</ul></li>
</ul></li>
<li><a href="#networking" id="toc-networking">Networking</a>
<ul>
<li><a href="#definition-4" id="toc-definition-4">Definition</a></li>
</ul></li>
<li><a href="#security" id="toc-security">Security</a>
<ul>
<li><a href="#definition-5" id="toc-definition-5">Definition</a>
<ul>
<li><a href="#namespaces" id="toc-namespaces">Namespaces</a></li>
<li><a href="#control-groups" id="toc-control-groups">Control
groups</a></li>
<li><a href="#capabilities-1"
id="toc-capabilities-1">Capabilities</a></li>
<li><a href="#mandatory-access-control-systems"
id="toc-mandatory-access-control-systems">Mandatory access control
systems</a></li>
<li><a href="#seccomp-1" id="toc-seccomp-1">Seccomp</a></li>
</ul></li>
<li><a href="#conclusion" id="toc-conclusion">Conclusion</a></li>
<li><a href="#swarm-security" id="toc-swarm-security">Swarm
security</a></li>
<li><a href="#swarm-join-tokens" id="toc-swarm-join-tokens">Swarm join
tokens</a></li>
<li><a href="#tls-and-mutual-authentication"
id="toc-tls-and-mutual-authentication">TLS and mutual
authentication</a></li>
<li><a href="#cluster-store" id="toc-cluster-store">Cluster
store</a></li>
<li><a href="#signing-images" id="toc-signing-images">Signing
images</a></li>
<li><a href="#secrets" id="toc-secrets">Secrets</a></li>
</ul></li>
</ul>
</nav>
<h1 id="introduction">Introduction</h1>
<p>Applications run businesses if applications break businesses suffer
and sometimes go away, these statement get truer every day. Most
applications run on servers. And in the past, we could only run one
application per server, the open systems world of Windows and Linux just
did not have the technologies to safely and securely run multiple
applications on the same server. So the story usually went something
like this - every time the business needed a new application IT
department would go out and buy a new server, and most of the time
nobody knew the performance requirements of the new application ! This
meant IT had to make guesses when choosing the model and size of servers
to buy.</p>
<p>As a result, IT did the only thing it could do - it bought big fast
servers with lots of resiliency. After all ,the last thing anyone wanted
- including the business was under powered servers, under powered
servers might be unable to execute transactions which might result in
lost customers and lost revenue. So IT usually bought bigger servers
than were actually needed. This resulted in huge numbers of servers
operating as low as 5-10% of their potential capacity. A tragic waste of
company capital and resources.</p>
<h2 id="vmware">VMware</h2>
<p>Amid all of this, <code>vmware</code>, gave the world a gift - the
virtual machine. And almost overnight the world changed into a much
better place, We finally had a technology that would let us safely and
securely run multiple business applications on a single server. This was
a game changer. IT no longer needed to procure a brand new oversized
server every time the business asked for a new application. More often
than not they could run new apps on existing servers that were sitting
around with spare capacity.</p>
<p>All of a sudden we could squeeze massive amounts of value out of
existing corporate assets such as servers resulting in a lot more bang
for the company’s buck. However there is always a but ! As great as
virtual machines are they are not perfect, the fact that every virtual
machine requires it own dedicated OS is a major flaw, every OS consumes
CPU, RAM and storage that could otherwise be used to power more
applications, Every OS needs patching and monitoring. And in some cases
every OS requires a license. All of this is a waste of op-ex and cap-ex.
The virtual machine model has other challenges too. Virtual machines are
slow to boot and portability is not great - migrating and moving virtual
machine workloads between <code>hypervisors</code> and cloud platforms
is harder than it needs to be.</p>
<h2 id="containers">Containers</h2>
<p>For a long time the big web-scale players like google have been using
container technologies to address these shortcomings of the
<code>VM</code> model. The container model the container is roughly
analogous to the virtual machine. The major difference though, is that
every container does not require a full blown OS. In fact all containers
on a single host share a single OS. This frees up huge amounts of system
resources such as CPU, RAM and storage. It also reduces potential
licensing costs and reduces the overhead of OS patching and other
maintenance. This results in savings on the <code>ap-ex</code> and
<code>op-ex</code> fronts. Containers are also fast to start and
ultra-portable. Moving container workloads from your laptop to the cloud
and then to virtual machines or bare metal in your data center is a
breeze.</p>
<h3 id="linux-containers">Linux containers</h3>
<p>Modern containers, started in the Linux world and are the product of
an immense amount of work from a wide variety of people over a long
period of time. Just as one example, Google has contributed many
container related technologies to the Linux kernel. Without these and
other contributions we would not have modern containers today. Some of
the major technologies that enabled the massive growth of containers in
recent years include <code>kernel namespaces</code> and
<code>control groups</code> and of course - <code>Docker</code>. Despite
all of this work, containers remained complex and outside of the reach
of most organizations, it was not until docker came along that
containers were effectively democratized and accessible to the
masses.</p>
<h3 id="windows-containers">Windows containers</h3>
<p>Over the past few years, Microsoft, has worked extremely hard to
bring docker and containers technologies to the windows platform. The
core windows technologies required to implement containers are
collectively referred to as Windows Containers. The user space tooling
to work with these containers is docker.</p>
<h3 id="mac-containers">Mac containers</h3>
<p>There is currently no such thing as Mac containers, however one can
use Linux containers on a mac using the Docker for mac product. This
works by seamlessly running your containers inside of a
<code>lightweight Linux VM running on the Mac</code>.</p>
<h3 id="windows-vs-linux-containers">Windows vs Linux containers</h3>
<p>It is vital to understand that a running container uses the kernel of
the host machine it is running on. This means that a container designed
to run on a host with a Windows kernel will not run on a Linux host.
This means that one can think of it like this a at a high level -
Windows containers require windows host, and Linux containers require a
Linux host. It is however possible to run Linux containers on Windows
machines, using the Docker for <code>Windows or WSL</code>. This is an
area that is developing fast.</p>
<h1 id="docker">Docker</h1>
<p>What is docker really, that could refer to three things:</p>
<ul>
<li>Docker, Inc - is the company behind the docker project</li>
<li>Docker the container <code>runtime</code> and orchestration
technology</li>
<li>Docker the open source project - also called <code>Moby</code></li>
</ul>
<h2 id="docker-inc">Docker, Inc</h2>
<p>Docker is a software that runs on Linux and Windows. It creates,
manages and orchestrates containers. The software is developed in the
open part of the <code>Moby</code> open-source project on
<code>github</code>. Docker, Inc is a company based out of San Fran, and
is the overall maintainer of the project. There is also a commercial
version Docker with more support and contracts. The company is founded
by <code>Solomon Hykes</code>. Interestingly, Docker started its life as
a platform as a service, provider called <code>dotCloud</code>. Behind
the scenes, the <code>dotCloud</code> platform leveraged Linux
containers. To help them create and manage these containers they built
an internal tool that they named Docker</p>
<p>In 2013 the <code>dotCloud</code> <code>PaaS</code> business was
struggling and the company needed a new lease of life. To help with this
they hired <code>Ben Gloub</code> as new CEO, <code>rebranded</code> the
company as Docker, Inc got rid of the <code>dotCloud</code> platform,
and started a new journey with a mission to bring docker and containers
to the world. Today Docker, Inc, is widely recognized as an innovative
technology company with a market valuation said to be in the billions.
Since becoming Docker, Inc they have made several small acquisitions for
undisclosed fees, to help grow their portfolio of products and
services.</p>
<h2 id="docker-runtime-and-orchestration">Docker runtime and
orchestration</h2>
<p>When most technologists talk about Docker they are referring to the
Docker engine, The docker engine is the infrastructure plumbing software
that runs and orchestrates containers. If you are a <code>VMware</code>
admin you can think of it as being similar to <code>ESXi</code>. In the
same way that <code>ESXi</code> is the core <code>hypervisor</code>
technology that runs virtual machines, the Docker Engine is the core
container that <code>runtime</code> that runs containers. All other
Docker, Inc, and 3rd party products plug into the Docker Engine and
build around it.</p>
<h2 id="docker-project---moby">Docker project - MOBY</h2>
<p>The term docker is also used to refer to the open source Docker
project. This is the set of tools that get combined into things like the
docker <code>deamon</code>, and client you can download and install from
the docker.com host. However the project was officially renamed as the
<code>Moby</code> project at <code>DockerCon</code> in 2017. The goal of
the <code>Moby</code> project is to break Docker down into more modular
components and to do this, in the open. It is hosted on GitHub and you
can see a list of the current sub-projects and tools included in the
<code>Moby</code> repository. The core Docker Engine project is
currently located at <code>https://github.com/moby/moby</code>. As an
open-source project the source code is publicly available and you are
free to download it, contribute to it, tweak it and use it, as long as
you adhere to the license.</p>
<p>Looking at the commit history, one will immediately notice that some
of the contributors are companies as
<code>RedHat, Microsoft and IBM, Cisco and HPE</code>. Most of the
project and its tools are written in <code>golang</code>, the relatively
new system level programming language from Google also known as Go.</p>
<h2 id="container-ecosystem">Container ecosystem</h2>
<p>Once of the core philosophies at Docker is often referred to as
Batteries included but removable. This is a way of saying you can swap
out a lot of the native Docker stuff and replace it with stuff from 3rd
parties. A good example of this is the networking stack. The core Docker
product ships with built in networking, but the networking stack is
pluggable meaning you can rip out the native Docker networking and
replace it with something else from a 3rd party</p>
<p>In the early days it was common for 3rd party plugins to be better
than the native offerings that shipped with docker. However this
presented some business model challenges for Docker, After all, Docker
has to turn a profit at some point to be a viable long term business. As
a result, the batteries that are included are getting better and
better.</p>
<h2 id="open-container-initiative">Open container initiative</h2>
<p>The <code>OCI</code> is a relatively new governance council
responsible for standardizing the most fundamental components of
container infrastructure such as image format and container
<code>runtime</code>. It is also true that no discussion of the OCI is
complete without mentioning a bit of history. And as with all accounts
of history, the version you get depends on who is doing the talking.</p>
<p>From day one, use of Docker has grown like crazy. More and more
people used it in more and more ways for more and more things, so it was
inevitable that somebody was going to get frustrated, this is normal.
The <code>TLDR</code> of this history according to Nigel is that a
company called <code>COREOS</code> did not like the way docker did
certain things. So they did something about it. They created a new open
standard called <code>APPC</code> that defined things like image format
and container <code>runtime</code>. They also created an implementation
of the spec called <code>rkt</code> - pronounced rocket. This put the
container ecosystem in an awkward position with two competing
standards</p>
<p>This threatened to fracture the ecosystem and presented users and
customers with a dilemma. While competition is usually a good thing,
competing standards is not. This caused confusion and slowdown of user
adoption. Not good for anybody, with this in mind everybody did their
best to act like adults, and came together to form the <code>OCI</code>
- a lightweight agile council to govern container standards. The
<code>OCI</code> has published two specifications - image-spec and
<code>runtime-spec</code>. An analogy that is often used when referring
to these two standards is rail tracks. These two standards are like
agreeing on standard sizes and properties of rail tracks. Leaving
everyone else free to build better trains carriages better signaling
systems better stations, all safe in the knowledge that they will work
on the standardized tracks. Nobody wants two competing standards for
rail track sizes</p>
<h2 id="kernel">Kernel</h2>
<p>Control groups and namespaces are foundational features in the Linux
kernel that enable containerization by providing resource control and
isolation. Together they form the building blocks for container runtimes
like Docker, Podamn and Kubernetes. To appreciate their role it is
essential to understand each in depth and how they synergize to create
the container abstraction.</p>
<h3 id="control-groups-cgroups">Control groups (cgroups)</h3>
<p>Control groups are a Linux kernel feature that provides mechanisms
for limiting prioritizing and monitoring the usage of system resource
such as CPU, memory and disk I/O, and network bandwidth. Introduced in
2007, cgroups allow processes to be grouped hierarchically and to apply
resource constraints or quotas at at the group level. Cgroups work by
organizing processes into “control groups”, which are hierarchical
structures where resource limits and accounting are defined. This
hierarchy is represented as virtual filesystem (often mounted at
<code>/sys/fs/cgroup</code>), with directories corresponding to cgroups.
Each cgroup can enforce specific limits to priorities for a particular
type of resource. For instance:</p>
<ol type="1">
<li><p>CPU and CPU Shares: Cgroups allow limiting the amount of CPU time
a process or group of processes can use. For example, if two containers
are running on the same host, you can allocate more CPU time to one
container over the other.</p></li>
<li><p>Memory Limits: By setting memory constraints, cgroups ensure that
a process cannot exceed a specific memory threshold, thereby preventing
memory exhaustion on the host system.</p></li>
<li><p>Block in/out network bandwidth: these can be throttled to ensure
fair sharing among processes or to priorities critical
workloads.</p></li>
</ol>
<p>Cgroups are hierarchical, meaning resource limits propagate downward
in the tree. This hierarchy enables complex configurations, such as
allocating a fixed percentage of CPU to a parent cgroup and then
subdividing that allocation among child cgroups.</p>
<p>Without cgroups processes running on the same host would contend for
resources without constraints leading to potential resource starvation
or overuse. In the context of containers, cgroups ensure that each
container operates within its allocated resources, making them
predictable, and performant even in multi tenant environment.</p>
<h3 id="namespaces-namespaces">Namespaces (namespaces)</h3>
<p>Namespaces, another Linux kernel feature isolate global system
resources for groups of processes, by scoping resources, namespaces
provide the illusion that a process or group of processes is running on
its own system, separate from the others. This isolation is the backbone
of containerization, as it ensures that processes inside a container are
unaware of and unaffected by the processes and resources outside their
namespace.</p>
<p>There are several types of namespaces, each targeting a specific
system resource or function:</p>
<ol type="1">
<li><p>PID Namespace: Provides isolation for process ID. Processes
inside a PID namespace see a separate process tree starting from PID 1,
often the init system within the container. This ensures that processes
in one container cannot see or signal processes in another container or
the host</p></li>
<li><p>Mount namespace: isolates filesystem mount points. Each container
can have its own root filesystem and mount points separate from the host
or other containers. This is critical for providing a private file
system view for containers.</p></li>
<li><p>UTS namespace: isolates system identifiers such as host name
domain name. This allows containers to have their own hostname decoupled
from the host system’s identity</p></li>
<li><p>Network namespace: isolates network resources, including IP
addresses routing tables and sockets. Containers can have their own
virtual network interfaces and IP address, managed independently of the
host or other containers.</p></li>
<li><p><code>IPC</code> namespace: isolates inter process communication
resources, such as shared memory and semaphores ensuring that contains
cannot inadvertently interfere with one another’s IPC
mechanisms</p></li>
<li><p>User namespace: provides user and group ID isolation , allowing
process inside a container to have different user ID from the
host.</p></li>
</ol>
<p>By leveraging namespaces each container can function as if it is
running on a standalone system with a private set of resources. However,
the host kernel orchestrates and manages these namespaces allowing
containers to coexist on a shared kernel.</p>
<h3 id="cgroup-namespaces">Cgroup &amp; Namespaces</h3>
<p>Cgroups and namespace complement each other to create the container
abstraction:</p>
<ol type="1">
<li><p>Isolation - namespaces ensure that a container processes ,
network, filesystem and other system resources are isolated from the
host and from the other containers. This isolation is crucial for
security and the lightweight vitalization illusion that containers
offer.</p></li>
<li><p>Resource control - control groups regulate how much of the
resources isolated by the namespaces a container can consume, this
combination prevents resource contention ensuring fair and predictable
usage.</p></li>
</ol>
<p>For example a container running a web server might operate within its
own network namespace, with its own virtual NIC and IP address, mount
namespace, with a private filesystem view, and PID namespace, with its
own process tree. Simultaneously, cgroups ensure that the container
cannot exceed 512MB of RAM and 50% of the CPU usage.</p>
<h2 id="containerization">Containerization</h2>
<p>Containers are not independent operating systems like virtual
machines, they are processes running on the host operating system,
constrained and isolated by cgroups and namespaces. These technologies
allow containers to share the host kernel while appearing isolated,
enabling the following key benefits</p>
<ol type="1">
<li><p>Lightweight - since containers share the host kernel, the require
far fewer resources than VM which emulate hardware and run separate OS
instances.</p></li>
<li><p>Fast start and shutdown - containers start quickly because they
do not boot an entire operating system. They are essentially just
processes with extra isolation, running on the host, just any other user
level user process</p></li>
<li><p>Scalability - with cgroups enforcing resource limits, many
containers can run concurrently on the same host without over
provisioning</p></li>
</ol>
<p>Modern container runtimes like Docker encapsulate these capabilities
by automating the creation and management of namespaces and cgroups for
each container, Tools like Kubernetes further build on this foundation
to orchestrate containers across distributes systems, ensuring high
availability and scalability.</p>
<p>In conclusion cgroups and namespaces by isolating and managing
resources, transform the Linux kernel into a powerful platform for
containerization. They encapsulate processes in a lightweight portable
and secure manner, paving the way for the cloud native ecosystem that
underpins much of today’s software industry and infrastructure</p>
<h2 id="more-kernel-components">More kernel components</h2>
<p>Beyond the already mentioned components the Linux kernel contains a
lot of other components which facilitate the deployment and
containerization of applications as we know them nowadays. Here are some
of them</p>
<h3 id="overlayfs">OverlayFS</h3>
<p>That is a union filesystem that allows multiple layers of filesystems
to be stacked. It plays a key role in containerization by enabling the
creation of lightweight writable layers on top of read-only image
layers. The way it works is that when a container is created, a writable
layer is added on top of a resad only base image. Any modification made
by the container are written to this top layer, while the base image
remains unchanged. This enables:</p>
<ul>
<li>Efficient sharing of base images between containers.</li>
<li>Minimal disk usage since only changes are stored.</li>
<li>Fast container creation by simply stacking layers</li>
</ul>
<p>In containers the <code>OverlayFS</code> underpins the storage driver
mechanism in Docker and other container runtimes, making image building
sharing and running highly efficient.</p>
<h3 id="seccomp">Seccomp</h3>
<p>Seccomp is a Linux kernel security feature that restricts the system
calls (syscalls) a process can make. Containers use seccomp to reduce
the attack vector / surface by preventing them from invoking potentially
dangerous syscalls. The way this works is that seccomp operates as
syscall filter. A process or container is provided with a list of
allowed syscalls, any syscall not on the list is blocked. This is
typically configured using a seccomp profile.</p>
<p>In containerization this play key role in protecting the host from
container exploits by limiting access to sensitive syscalls, enables
fine grained control over what containers can and cannot do or
execute</p>
<h3 id="capabilities">Capabilities</h3>
<p>Linux capabilities break down the all powerful root privileges into
discrete units of authority. Containers often run as root within their
own namespaces but they are stripped of unnecessary capabilities to
mitigate risks. The way this works is by having the kernel allowing
processes to drop or retain specific capabilities, like CAP_NET_ADMIN,
for network management. For example a container may have the ability to
bind to privileged ports but not modify kernel parameters</p>
<p>In containerization this enhances security by limiting what
containers can do, even when running as root, reduces the risk of
privilege escalation.</p>
<h3 id="apparmor-selinux">AppArmor &amp; SELinux</h3>
<p>These are two kernel frameworks for enforcing mandatory access
control (MAC) policies. These frameworks restrict how applications or
containers interact with the system. The way they work is that AppArmor
defines file and process level access policies for containers, it is
path-based meaning access is controlled based on file paths. SELinux
uses labels to define granular access policies for processes, files and
other resources.</p>
<p>In containerization ensures that containers can only access files,
directories and resources explicitly allowed by their profiles or
labels, also protects the host system from compromised or malicious
containers.</p>
<h3 id="capabilities-nnp">Capabilities &amp; NNP</h3>
<p>Beyond capabilities the “No New Privileges” is a kernel flag feature
that ensures a process cannot gain additional privileges through
mechanism like <code>setuid</code> binaries. The way this works is that
when <code>NNP</code> is enabled, even if a containerized process runs a
binary with <code>setuid</code> permissions, it cannot escalate its
privileges.</p>
<p><code>setuid - short for set user identity allow users to run an executable with the file system permissions of the executable's owner, and to change behavior in directories. They are often used to allow users on a computer system to run programs with a temporarily elevated privileges to perform a specific task.</code></p>
<h3 id="device-control">Device control</h3>
<p>The Linux kernel provides mechanism for controlling access to
hardware devices through the device cgroup and the <code>mknod</code>
syscall. The way this works is that the device cgroup allows fine
grained control over which devices a container can access - block
devices, character devices etc. Containers can also be restricted from
creating new device nodes using <code>mknod</code></p>
<p>In containerization prevents unauthorized access to host devices like
storage or network interfaces, limits the potential for containers to
interact directly with sensitive hardware</p>
<h3 id="network-virtualization">Network virtualization</h3>
<p>Linux networking stack provides features that are critical for
container networking, including virtual Ethernet (<code>veth</code>)
pairs, network bridges and like <code>iptables</code>. The way this
works containers are typically connected to the host network through
virtual Ethernet pairs, where one end resides in the container’s network
namespace and the other in the host’s namespace or bridge. Network
bridges like <code>docker0</code> or <code>CNI</code> plugins create
virtual networks to interconnect containers</p>
<h3 id="resource-limits">Resource limits</h3>
<p>Resource limits - <code>rlimits</code> provide per-process controls
over resources like file descriptors, stack size, and CPU time. While
not as flexible as cgroups, <code>rlimits</code> play a complementary
role in containerized environments. The way this works is that
<code>rlimits</code> are set using the <code>setrlimit</code> syscall,
constraining individual process behavior.</p>
<p>In containerization it is used to impose additional resource
restrictions at the process level, prevents runaway resource consumption
within a container by a rogue process</p>
<h1 id="components">Components</h1>
<p>The idea of this chapter is to give you a quick big picture of what
Docker is all about before we dive in deeper in later chapters.</p>
<h2 id="images">Images</h2>
<p>A good way to think of a Docker image is an object that contains a
<code>filesystem</code> and an application. If you work in operations,
it is like a virtual machine template. Another analogy that could be
made is that the image is like a class definition, while the container
is like an instance of a class. Getting images onto your Docker host is
called pulling.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to pull the target image locally</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull ubuntu:latest</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># to display all the images locally</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image ls</span></code></pre></div>
<p>There are other interesting images such as the
<code>microsoft/powershell</code> image, which contains the
<code>windows nano server</code> with a <code>powershell</code>. Or the
<code>microsfot/iis</code> image which in turn contains and image with
an <code>IIS</code></p>
<h2 id="containers-1">Containers</h2>
<p>After an image has been pulled locally on the docker host daemon, the
<code>docker container run</code> command can be used to launch an
instance of this container.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container run <span class="at">-it</span> microsoft/powershell:nanoserver PowerShell.exe</span></code></pre></div>
<p>If one looks closely at the output from the command above, notice
that the shell prompt has changed. This is because your shell is now
attached to the shell of the new container. The -it flag tells the
daemon to make the container interactive and to attach our current
terminal to the shell of the container. It also tells the container to
start the <code>PowerShell</code> executable before attaching and after
starting the container. To list the containers currently created and/or
running, one can use the following command</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># this command will list all containers ever crated, running or stopped, along with the container id and container name,</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># status and the image the container is started with</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container ls</span></code></pre></div>
<h3 id="attaching">Attaching</h3>
<p>Once a container is running, one can also attach to it, with the
docker exec command, as the container from the previous steps is still
running, one can attach to it with
<code>docker container exec -it &lt;container-id | container-name&gt; &lt;command-name&gt;</code></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the id here is an example id of a running container, this id can be obtained from the docker container ls command</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container exec <span class="at">-it</span> e2b69eeb5cb bash</span></code></pre></div>
<p>The <code>&lt;command-name&gt;</code> above tells the container which
process to start within the container when attaching to the
container.</p>
<h3 id="stopping">Stopping</h3>
<p>To stop the container one can do that using the
<code>docker container stop &lt;container-id | container-name&gt;</code>,
this will stop the container but it will still remain ready to be
started again with <code>docker container start</code> however one can
also remove the container using <code>docker container rm</code>
instead</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container stop e2b69eeb5cb</span></code></pre></div>
<h3 id="removing">Removing</h3>
<p>To remove a container, removing and deleting all resources associated
with it, one should use the
<code>docker container rm &lt;container-id | container-name&gt;</code>
command instead, this will completely remove all container resources, ,
however the image the container was created with will not be removed,
since it is not part of the container’s resources</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container rm e2b69eeb5cb</span></code></pre></div>
<h2 id="dockerfile">Dockerfile</h2>
<p>Usually some user applications have an additional file which is used
to build on top of existing docker images, those are called
<code>Dockerfile</code>, actually, the base images are also
<code>Dockerfiles</code> as well, in essence.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> alpine</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">LABEL</span> maintainer=<span class="st">&quot;yourname@hotmail.com&quot;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">apk</span> add <span class="at">--update</span> nodejs nodejs-npm</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> . /src</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">WORKDIR</span> /src</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">npm</span> install</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="kw">EXPOSE</span> 8080</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;node&quot;</span>, <span class="st">&quot;./app.js&quot;</span>]</span></code></pre></div>
<p>The <code>Dockerfile</code> represents an image, just like the base
images, the difference is that they usually build on top of some base
image, custom user rules. In the example above, the
<code>Dockerfile</code> creates an image which is based on the alpine
base image, however it enhances it by installing node, the base alpine
version has only the regular <code>coreutil</code> applications</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># execute this command from a directory which contains a Dockerfile</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image build <span class="at">-t</span> test:latest .</span></code></pre></div>
<p>To create an image from a custom <code>Dockerfile</code>, one can use
the following command above, this will create an image called test, with
the version of latest, the -t argument refers to the process of tagging
an image, or in other words putting an identifier on the image</p>
<p><code>Note that each command/line above in the Dockerfile creates what is called a layer, the layers is what docker deamon uses internally to build the images, each layer is built independently, meaning that if one layer changes that is the only layer that is going to be re-build, which makes modifying images very quick and efficient.</code></p>
<h2 id="docker-engine">Docker engine</h2>
<p>The docker engine is the core software that runs and manages the
containers, we often refer to it as simply as Docker, or the docker
platform. If you know a thing or two about VMware it might be useful to
think of it as being like ESXi in the VMware world. The Docker engine is
modular in design with many swappable components, where possible these
are based on open standards outlined by the OCI.</p>
<p>In many ways the docker engine is like a car engine - both are
modular and created by connecting many small specialized parts. The
major components that make up the docker engine are - Docker cilent,
Docker daemon, containerd and runc. Together they create and run
containers.</p>
<p>When docker was first released, the docker engine had two major
components - the <code>deamon</code> and <code>LXC</code>. The daemon
was a monolithic binary, It contains all of the code for the docker
client, the docker api, the container <code>runtime</code> image builds
and much more. The <code>LXC</code> component provided the
<code>deamon</code> with access to the fundamental building blocks of
containers such as kernel <code>namespaces</code> and control groups.
The docker daemon was using the <code>LXC</code> to interact with the
host kernel.</p>
<p>To get rid of the <code>LXC</code> was an issue, first it is Linux
specific, this was a problem for a project that had aspirations of being
cross platform. Second up being reliant on an external tool for
something so core to the project was a huge risk that could hinder
development, as a result the Docker, Inc developed their own tool called
<code>libcontainer</code> as a replacement for <code>LXC</code>. The
goal of <code>libcontainer</code> was to be a platform agnostic tool
that provided Docker with access to the fundamental container building
blocks that exist inside the OS.</p>
<p>To get rid of the monolithic <code>deamon</code>, the aim was to
break out as much of the functionality as possible from the
<code>deamon</code>, and re-implement it in smaller specialized tools.
These specialized tools can be swapped out as well as easily used by
third parties to build other tools. This plan followed the UNIX
philosophies of building small specialized tools that can be pieced
together into large tools. This breaking down process is still ongoing,
however it has already seen all of the container execution and container
runtime code entirely removed from the daemon and refactored into small
specialized tools such as runc (container runtime) and containerd
(container supervisor)</p>
<ul>
<li><p>runc - as already mentioned <code>runc</code> is the reference
implementation of the OCI container runtime spec, Docker, Inc was
heavily involved in defining the spec and developing runc. Runc is
small, it is effectively a lightweight CLI that wraps around
<code>libcontainer</code>, it has a single purpose in life - to create
containers.</p></li>
<li><p>containerd - in order to use <code>runc</code>, the Docker engine
needed something to act as a bridge between the <code>deamon</code> and
<code>runc</code>. This is where <code>containerd</code> comes into the
picture. <code>Containerd</code> implements the execution logic that was
pulled out of the Docker daemon, this logic was obviously refactored and
tuned when it was written as <code>containerd</code>.
<code>Containerd</code> is a container supervisor - it is responsible
for container <code>lifecycle</code> operations such as starting and
stopping containers, pausing and un-pausing them and destroying them.
Like <code>runc</code> <code>containerd</code> is small lightweight and
designed for a single task in life - only interested in container
<code>lifecycle</code> operations.</p></li>
</ul>
<p>The most common way of starting containers is using the Docker CLI.
The following docker container run command will start a simple new
container based on the alpine:latest image</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode sh"><code class="sourceCode bash"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container run <span class="at">--name</span> ctr1 <span class="at">-it</span> alpine:latest sh</span></code></pre></div>
<p>When this command is typed int the docker <code>CLI</code>, the
docker client converts them into the appropriate API payload and POSTS
them to the correct API endpoint. This API is implemented in the daemon,
it is the same rich versioned, REST API that has become a hallmark of
Docker and is accepted in the industry as a de-facto container API. Once
the <code>deamon</code> receives the command to create a new container
it makes a call to <code>containerd</code>. The daemon communicates with
<code>containerd</code> via a CRUD like API over <code>gRPC</code>.
Despite its name <code>containerd</code> cannot actually create
containers, it uses <code>runc</code> to do that. It converts the
required Docker image into an <code>OCI</code> bundle and tells
<code>runc</code> to use this to create a new container.
<code>Runc</code> interfaces with the OS kernel to pull together all of
the constructs necessary to create a container, in Linux these include
<code>namespaces</code> and <code>cgroups</code>. The container process
is started as a child process of <code>runc</code>, and as soon as it is
started <code>runc</code> will exit. The benefit of this approach is
that one can perform updates to the Docker daemon or the
<code>containerd</code> without affecting, the containers.</p>
<p>There is a special component between the <code>containerd</code> and
<code>runc</code>, called <code>shim</code>. The shim is integral to the
implementation of the <code>deamonless</code> containers, i.e decoupling
running a container from the daemon for things like upgrading the
<code>deamon</code> without killing containers. As already shown,
containerd uses <code>runc</code> to create a new container, in fact it
forks a new instance of runc for every container it creates. However
once each container is created its parent <code>runc</code> process
exits. This means we can run hundreds of containers without having to
run hundreds of runc instances. Once a container’s parent
<code>runc</code> terminated, the associated containers-shim process
becomes the container’s parent process. Some of the responsibility of
the shim performs a container’s parent include</p>
<ul>
<li><p>keeping any stdin and stdout streams open so that when the
<code>deamon</code> is restarted the container does not terminate due to
pipes being closed.</p></li>
<li><p>reports the container’s exit status back to the daemon.</p></li>
</ul>
<p>On a Linux system the components we have discussed are implemented as
separate binaries as follows:</p>
<ul>
<li>dockerd (<code>deamon</code>)</li>
<li>docker-containerd (containerd)</li>
<li>docker-containerd-shim (shim)</li>
<li>docker-runc (runc)</li>
</ul>
<p>All of those can be seen running if one runs the <code>ps</code>
command in the host. Some of them will be present when the system has
running containers only, like the shim, or when a container is starting,
like runc.</p>
<h1 id="deep-dive">Deep-dive</h1>
<h2 id="images-1">Images</h2>
<p>Once can think as images as being like VM templates. A VM template is
like a stopped VM - a Docker image is like a stopped container. The
images are usually pulled from a registry. The most popular registry is
the Docker Hub, but other do exist. The pull operation downloads the
image to the host machine, where it can be used to start one or more
docker containers. Images are made up of multiple layers that get
stacked on top of each other and represented as single object. Inside of
the image is a cut-down operating system and all of the files and
dependencies required to run an application. Because containers are
intended to be fast and lightweight images tend to be small.</p>
<h3 id="definition">Definition</h3>
<p>As mentioned a couple of times already that images are like stopped
containers (or classes, coming from the programming world). In fact one
can stop a container and create a new image from it. With this in mind,
images are considered a build time constructs where as containers are
run-time constructs. One can think of images as a snapshot of a
container in a given</p>
<p>The whole purpose of a container is to run an application or service,
this means that the image a container is created from must contain all
OS and application files required to run the service. However,
containers are all about bein fast and lightweight. This means that the
images they are build from are usually small and stripped of all
non-essential parts. For example Docker images do not sip with 6
different shells, they do not contain a kernel, all containers running
on a docker host share access to the host’s kernel. For these reasons we
sometimes say images contain just enough operating system - usually OS
related files and filesystem objects. The official Alpine Linux docker
image is about <code>4mb</code>, in size and is an extreme example of
how small Docker images can be. The official Ubuntu Docker image which
is currently about 120MB. Windows based images tend to be bigger than
Linux ones, because of the way that the Windows OS works, For example
the latest Microsoft .NET image is over 2GB when pulled and
uncompressed, the windows server nano (2016) is slightly over 1GB.</p>
<h3 id="pulling">Pulling</h3>
<p>Pulling images is the process of getting images onto a Docker host.
These images are usually pulled from what is called image registries.
Docker images are stored in these registries. The most common registry
is the Docker Hub. Other registries exist, including 3rd party
registries and secure on-premise registries. However the docker client
is opinionated and defaults to the Docker Hub. Image registries contain
multiple image repositories, in turn these repositories contain multiple
images. Let us take the Ubuntu image as example - it is one of many
repositories in the registry, the Ubuntu repository in turn has many
versions of the Ubuntu image. The Docker hub has a concept of official
repositories and unofficial ones. As the name suggests official
repositories contain images that have been vetted by Docker. This means
they should contain up-to-date high quality code that is secure
well-documented and in line with best practices, Unofficial repositories
can be like the wild west - you should not expect them to be safe, well
documented, or even work. That is not saying everything in unofficial
repositories is bad. Most of the populate operating systems and
applications have their own official repositories. The are easy to spot
as they live at the top level of the Docker hub <code>namespace</code>.
These lie under the following URL formats -
<code>https://hub.docker.com/_/&lt;image&gt;</code> While personal
images are behind URL formats such as
<code>https://hub.docker.com/r/&lt;user&gt;/image</code></p>
<ul>
<li><code>nginx</code> - <a href="https://hub.docker.com/_/nginx"
class="uri">https://hub.docker.com/_/nginx</a></li>
<li><code>busybox</code>- <a href="https://hub.docker.com/_/busybox"
class="uri">https://hub.docker.com/_/busybox</a></li>
<li><code>redis</code>- <a href="https://hub.docker.com/_/redis"
class="uri">https://hub.docker.com/_/redis</a></li>
<li><code>mongo</code> - <a href="https://hub.docker.com/_/mongo"
class="uri">https://hub.docker.com/_/mongo</a></li>
</ul>
<h3 id="names">Names</h3>
<p>Addressing images from the official repositories is as simple as
giving the repository name and tag separated by a colon (:). The format
for docker image pull when working with an image from an official
repository is -
<code>docker image pull &lt;repository&gt;:&lt;tag&gt;</code>. For
example one can easily pull a given version of an image using the
following commang</p>
<div class="sourceCode" id="cb10"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This will pull the image tagged as 3.3.11, from the official mongo repository</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull mongo:3.3.11</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># This will pull the image tagged as latest, from the official redis repository</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull redis:latest</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># This will pull the image tagged as latest, from the official alpine repository</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull alpine</span></code></pre></div>
<p>Note that even though the alpine example above does not specify any
version, by default the latest one is assumed. Another point, the latest
tag does not have any magical powers, just because an image is tagged as
latest, does not guarantee it is the most recent image in the
repository. For example the most recent image in the alpine repository
is usually tagged a edge. Latest in this case refers to the latest
stable version, but not the actual latest latest available</p>
<p>Pulling image from an unofficial repository is essentially the same -
the only difference is that the name of the repository is
<code>prepended in front</code>, using a forward slash as a separator
between the image name and the repository name.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here the image name is tu-demo, however the source repository is nigelpoulton</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull nigelpoulton/tu-demo:v2</span></code></pre></div>
<h3 id="tags">Tags</h3>
<p>The other important images with multiple tags, A single image can
have as many tags as want wishes, This is becaue tags are arbitrary
alpha-numeric values that are stored a metadata alongside the image, To
pull all images in a repository add the -a flag to the docker image pull
command.</p>
<div class="sourceCode" id="cb12"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This will all images, that are tagged in the repository nigelpoulton</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull <span class="at">-a</span> nigelpoulton/tu-demo</span></code></pre></div>
<p>Now since one image can have multiple tags, it is possible that the
command above pulls images where the latest image is actually such that
it already exists with another tag - say the <code>tu-demo</code> image
has three versions, <code>v1 and v2</code>, and latest, however it is
possible that the latest is actually also the one tagged as v2, in the
end the image pull command will simply pull two images -
<code>v1 and v2</code></p>
<h3 id="layers">Layers</h3>
<p>Docker image is just a bunch of loosely connected read only layers.
Docker takes care of stacking these layers and representing them as a
single unified object. There are few ways to see and inspect the layers
that make up an image, and we have already seen one of them.</p>
<div class="sourceCode" id="cb13"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull ubuntu:latest</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="ex">latest:</span> Pulling from library/ubuntu</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="ex">952132ac251a:</span> Pull complete</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="ex">82659f8f1b76:</span> Pull complete</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="ex">c19118ca682d:</span> Pull complete</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="ex">8296858250fe:</span> Pull complete</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="ex">24e0251a0e2c:</span> Pull complete</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="ex">Digest:</span> sha256:f4691c96e6bbaa99d...28ae95a60369c506dd6e6f6ab</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="ex">Status:</span> Downloaded newer image for ubuntu:latest</span></code></pre></div>
<p>Taking a look at the output of the pull command, one can see that
each line in the output above that ends with Pull complete, represents a
layer in the image, that was pulled. So the example image above has 5
layers. Another way to see the layers of an image is to inspect the
image with the docker image inspect command, the example below inspects
the same image, <code>ubuntu:latest</code></p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image inspect ubuntu:latest</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;Id&quot;</span><span class="ex">:</span> <span class="st">&quot;sha256:bd3d4369ae.......fa2645f5699037d7d8c6b415a10&quot;</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;RepoTags&quot;</span><span class="ex">:</span> [</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;ubuntu:latest&quot;</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;RootFS&quot;</span><span class="ex">:</span> {</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;Type&quot;</span><span class="ex">:</span> <span class="st">&quot;layers&quot;</span>,</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;Layers&quot;</span><span class="ex">:</span> [</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sha256:c8a75145fc...894129005e461a43875a094b93412&quot;</span><span class="ex">,</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sha256:c6f2b330b6...7214ed6aac305dd03f70b95cdc610&quot;</span><span class="ex">,</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sha256:055757a193...3a9565d78962c7f368d5ac5984998&quot;</span><span class="ex">,</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sha256:4837348061...12695f548406ea77feb5074e195e3&quot;</span><span class="ex">,</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;sha256:0cad5e07ba...4bae4cfc66b376265e16c32a0aae9&quot;</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>        <span class="ex">]</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="er">}</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="ex">]</span></span></code></pre></div>
<p>The trimmed output shows that the image has 5 layers, Only this time
they are shown using their <code>SHA256</code> hashes. However both
commands show that the image has 5 layers.</p>
<p><code>Note the docker history command shows the build history of an image and is not a strict lit of layers in the image, for example some Dockerfile instructions used to build an image do not result in layers being created. These include MAINTAINER, ENV, EXPOSE, ENTRYPOINT</code></p>
<p>All Docker images start with a base layer and as changes are made and
new content is added, new layers are added on top. Further more a newer
layer, can override, or obscure another older layer, meaning that if a
layer adds in a file in certain system directory, which is then added
again in the same location, under the same name, in another layer, it is
overridden, or stacked. Meaning that that allows one to build upon base
image layers, without having to modify the actual base layer itself.</p>
<div class="sourceCode" id="cb15"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull <span class="at">-a</span> nigelpoulton/tu-demo</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="ex">latest:</span> Pulling from nigelpoulton/tu-demo</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="ex">237d5fcd25cf:</span> Pull complete</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="ex">a3ed95caeb02:</span> Pull complete</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>Snip<span class="op">&gt;</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="ex">Digest:</span> sha256:42e34e546cee61adb100...a0c5b53f324a9e1c1aae451e9</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="ex">v1:</span> Pulling from nigelpoulton/tu-demo</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="ex">237d5fcd25cf:</span> Already exists</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="ex">a3ed95caeb02:</span> Already exists</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>Snip<span class="op">&gt;</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="ex">Digest:</span> sha256:9ccc0c67e5c5eaae4beb...24c1d5c80f2c9623cbcc9b59a</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="ex">v2:</span> Pulling from nigelpoulton/tu-demo</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="ex">237d5fcd25cf:</span> Already exists</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="ex">a3ed95caeb02:</span> Already exists</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>Snip<span class="op">&gt;</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="ex">eab5aaac65de:</span> Pull complete</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="ex">Digest:</span> sha256:d3c0d8c9d5719d31b79c...fef58a7e038cf0ef2ba5eb74c</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="ex">Status:</span> Downloaded newer image for nigelpoulton/tu-demo</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="va">$$</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image ls</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="ex">REPOSITORY</span> TAG IMAGE ID CREATED SIZE</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="ex">nigelpoulton/tu-demo</span> v2 6ac...ead 4 months ago 211.6 MB</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="ex">nigelpoulton/tu-demo</span> latest 9b9...e29 4 months ago 211.6 MB</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="ex">nigelpoulton/tu-demo</span> v1 9b9...e29 4 months ago 211.6 MB</span></code></pre></div>
<p>Sharing layers is also possible, between different images. This leads
to efficiencies in space and performance. For example when Docker pulls
images, with <code>docker image pull</code> command, Docker is smart
enough to recognize when it is being asked to pull an image layer that
is already has ac copy of. In this example the Docker pulled the image
tagged as latest first. Then when it went to pull v1 and v2 images it
noticed that it already had some of the layers that make up those
images. This happens because the three images in the repository are
almost identical, and therefore share many layers.</p>
<h3 id="digest">Digest</h3>
<p>So far we have shown how to pull images by tag, and this is by far
the most common way. But it has a problem - tags are mutable. This means
it is possible to accidentally tag an image with an incorrect tag.
Sometimes it is even possible to tag an image with the same tag as an
existing but different image, this can cause problems</p>
<p>As an example imagine that you have got an image called
<code>golftrack:1.5</code> and it has known bug, you pull the image
apply a fix and push the updated image back to its repository with the
same tag. Take a second to understand what just happened there. So what
just happened is that we have an image called <code>golftrack:1.5</code>
that has a bug. That image is being used in the production environment,
the image is pulled and fix is applied. Then comes the mistake the image
is pushed back with the fixed state, however under the same tag as the
vulnerable image.
<code>How are you going to know which of your production systems are running the vulnerable image and which are running the patched image, both images have the same tag !</code></p>
<p>This is where image digests come to the rescue. Docker introduced a
new content addressable storage model. As part of this model, all images
now get a <code>cryptographic</code> content hash. For the purposes of
this discussion we will refer to this hash as the digest. Because the
digest is a hash of the contents of the image, it is not possible to
change the contents of the image without the digest also changing. This
means digests are immutable, this helps to avoid the problem just
mentioned</p>
<p>Every time you pull an image the docker image pull command will
include the image’s digest as part of the return code. You can also view
the digests of the images in your Docker host’s lock repository by
adding the –digests flag to the docker image ls command, these are both
shown in the following example below.</p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image pull alpine</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="ex">Using</span> default tag: latest</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="ex">latest:</span> Pulling from library/alpine</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="ex">e110a4a17941:</span> Pull complete</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="ex">Digest:</span> sha256:3dcdb92d7432d56604d...6d99b889d0626de158f73a</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="ex">Status:</span> Downloaded newer image for alpine:latest</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image ls <span class="at">--digests</span> alpine</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="ex">REPOSITORY</span> TAG    DIGEST             IMAGE        ID CREATED   SIZE</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="ex">alpine</span>     latest sha256:3dcd...f73a 4e38e38c8ce0 10 weeks-ago 4.8 MB</span></code></pre></div>
<p>There is more to digests, since they represent the content of the
image, which is simply but the stack of layers which make up this image,
what happens when an image is uploaded, the layers are compressed to
save bandwidth, as well as space in the registry’s blob store. Cool but
compression a layer changes its content, this means that it’s content
hash will no longer match after the push or pull operations. This is a
problem. For example when you push an image layer to Docker Hub, Docker
hub will attempt to verify that the image arrived without being tampered
with en-route. To do this it turns a hash against the layer and checks
to see if it matches the hash that was sent with the layer. Because the
layer was compressed (changed) the has verification will fail. To get
around this each layer also gets something called a distribution hash,
this is a hash of the compressed version of the layer, when a layer is
pushed and pulled from the registry, its distribution hash is included
and this is what is used to verify that the layer arrived without being
tempered with. This content-addressable storage model vastly improves
security by giving us a way to verify image and layer data after push
and pull operations.</p>
<h3 id="architecture">Architecture</h3>
<p>Docker now includes support for multi platform and multi Architecture
images. This means a single image repository and tag to have an image
for Linux, Arm, PowerPc and so on. Other examples exist. To enable this
the Registry API supports a fat manifest as well as an image manifest.
Fat manifests list the architectures supported by a particular image,
whereas image manifests list the layers that make up a particular
image.</p>
<p>What happens is that when an image is pulled from the Docker hub, the
Docker client makes the relevant API requests to the registry, if a fat
manifest exists for that image, it will be parsed to see if an entry
exists for the current local host’s arch (assume as pull the image on a
local host which is an x86-64, Linux machine). It is exists the image
manifest for that image is retrieved and parsed for for the actual
layers that make up the image, the layers ae identified by their crypto
ID and are pulled from the registry’s blob store.</p>
<h3 id="deleting">Deleting</h3>
<p>When an image is no longer needed you can delete it from your docker
host, with the <code>docker image rm command</code>, rm is short for
remove. Images can be deleted by an ID or by the name of the image along
with the version, if a version is not provided, latest is assumed. If an
image is in use by a running container you will not be able to delete
it. A cool handy trick to remove all downloaded images which are
downloaded locally, along with their layers is to use the
<code>docker image rm</code> combined with the
<code>docker image ls -q</code> commands</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This will list all image ids on new lines such as, handy way to avoid using something like xargs, with docker rm</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image ls <span class="at">-q</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="ex">bd3d4369aebc</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="ex">4e38e38c8ce0</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># This will remove all images, which are currently not used by containers and also locally downloaded</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image rm <span class="va">$(</span><span class="ex">docker</span> image ls <span class="at">-q</span><span class="va">)</span> <span class="at">-f</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="ex">Untagged:</span> ubuntu:latest</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="ex">Untagged:</span> ubuntu@sha256:f4691c9...2128ae95a60369c506dd6e6f6ab</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:bd3d4369aebc494...fa2645f5699037d7d8c6b415a10</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:cd10a3b73e247dd...c3a71fcf5b6c2bb28d4f2e5360b</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:4d4de39110cd250...28bfe816393d0f2e0dae82c363a</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:6a89826eba8d895...cb0d7dba1ef62409f037c6e608b</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:33efada9158c32d...195aa12859239d35e7fe9566056</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:c8a75145fcc4e1a...4129005e461a43875a094b93412</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="ex">Untagged:</span> alpine:latest</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="ex">Untagged:</span> alpine@sha256:3dcdb92...313626d99b889d0626de158f73a</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:4e38e38c8ce0b8d...6225e13b0bfe8cfa2321aec4bba</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="ex">Deleted:</span> sha256:4fe15f8d0ae69e1...eeeeebb265cd2e328e15c6a869f</span></code></pre></div>
<h2 id="containers-2">Containers</h2>
<p>The container is the runtime instance of an image. In the same way
that we can start a virtual machine from a virtual machine template we
start one or more containers from a single image. The big difference
between a VM and a container is that containers are faster and more
lightweight instead of running a full-blown OS like a VM, containers
share the OS/kernel with the host they are running on</p>
<p>The simplest way to start a container is with the docker container
run command. The command can take a lot of arguments, but in its most
basic form you tell it an image to use and a command to run
<code>docker container run &lt;image&gt; &lt;command&gt;</code> -
e.g. <code>docker container run -it ubuntu/bin/bash</code>, or
<code>docker container run -it microsfot/powershell:nanoserver</code></p>
<p>Containers run until the program they are executing exists. In the
two examples above, the Linux container will exit when the bash shell
exits, and Windows container will exit when the PowerShell process
terminates. A really simple way to demonstrate this is to start a new
container and tell it to run the sleep command for 10 seconds. The
container will start, run for 10 seconds and exit -
<code>docker container run alpine:latest sleep 10.</code></p>
<p>To manually stop a running container, one can use the docker
container stop, which takes in the container id, then the container can
be started with the docker container start, again taking the container
id.</p>
<p>To remove a container or delete it, one can use the docker container
rm, again taking the container id as an argument, however one can not
delete a container that is running, it has to be stopped first</p>
<h3 id="definition-1">Definition</h3>
<p>Assume for the example above, a single physical server, which is
required to run 4 different applications, using either the virtual
machine or container approach</p>
<h4 id="vm-model">VM model</h4>
<p>In the VM model, the physical server is powered on and the hypervisor
boots, we are skipping the BIOS and bootloader code. Once the hypervisor
boots it lays claim to all physical resources on the system, such as
CPU, RAM, storage and NIC. The hypervisor then carves these hardware
resources into virtual versions that look smell and feel exactly like
the real thing. It then packages them into a software construct called a
virtual machine. We then take those virtual machines and install an
operating system and application on each one. We said we had a single
physical server and needed to run 4 applications, so we have created 4
virtual machines, install 4 operating systems and then install the 4
applications.</p>
<h4 id="container-model">Container model</h4>
<p>Things are a bit different in the container model. When the server is
powered on your chosen OS boots, in the docker world this can be Linux
or a modern version of Windows that has support for the container
primitives in its kernel. As per the VM model, the OS claims all
hardware resources. On top of the OS we install a container engine such
as Docker. The container engine then takes OS resources such as the
process tree, the filesystem and the network stack, and carves them up
into secure isolated constructs called containers. Each container looks
smells and feels like a real operating system. Inside of each container
we can run an application. Like before we are assuming a single physical
server with 4 applications. Therefore we would carve out 4 containers
and run a single application inside of each.</p>
<h4 id="comparison">Comparison</h4>
<p>At a high level we can say that the hypervisors perform hardware
virtualization the carve up physical hardware resources into virtual
versions. On the other hand the containers perform OS virtualization -
they carve up OS resources into virtual versions. In the virtual machine
model Every OS, consumes a slice of the processor, a slice of the
memory, a slice of the storage and so on. Most need their own licenses
as well as well as people and infrastructure to patch and upgrade them.
Each OS also presents a sizable attack surface. This is often called the
operating system tax, or the virtual machine tax, where every operating
system you install consumes way too many resources. The container models
has a single kernel running in the host operating system. It is possible
to run tens or hundreds of containers on a single host with every
container sharing that single kernel. That means a single operating
system, consuming the processor, memory, storage and other resources, a
single operating system that needs licensing, a single operating system
that need upgrading and patching, and a single operating system,
presenting an attack surface, all of that is a SINGLE operating system
tax bill !</p>
<h4 id="lifecycle">Lifecycle</h4>
<p>It is a common myth that containers can not persist data, they
certainly can. A big part of the reason people think containers are not
good for persistent workloads or persisting data, is because they are so
good at non persistence stuff. But begin good at one thing does not
meant you can not do the other well. Let us</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># start the container, name it percy and use the latest ubuntu image</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container run <span class="at">--name</span> percy <span class="at">-t</span> ubuntu:latest /bin/bash</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># add some persistent data to the container, create a new file</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> tmp</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span> <span class="at">-l</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">&quot;test&quot;</span> <span class="op">&gt;</span> newfile</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span> <span class="at">-l</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># press Ctrl-PQ to exit the container without killing it, using Ctrl-D will kill the process, in this case bash, and</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># will also kill the container, and exit</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co"># stop the container</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container stop percy</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co"># list all containers (use the -a flag, which is similar to the unix ls -a, to list all files)</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container ls <span class="at">-a</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co"># start the container back up</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container start percy</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co"># start a new bash process and attach to the container, one can also use the attach instead of exec to attach to an</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co"># already running process</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container exec <span class="at">-it</span> percy bash</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co"># attach to the process running in the container, that would by default attach to stdout, and only to stdin if the</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a><span class="co"># process was started interactively, with the -i flag</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container attach</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> temp</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a><span class="fu">ls</span> <span class="at">-la</span></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="co"># the `newfile` which was created above should be visible in the listing</span></span></code></pre></div>
<p>Now what is going on, when the container is first created with docker
container run the very first command it is started with will become the
new entrypoint, in this case this is /bin/bash. This is also started
with the <code>-t flag</code>, which creates a
<code>pseudo tty, which forces the process to not terminate</code>, in
this case we have a container running a persistent bash process, now
calling <code>docker container stop will stop the container</code>, but
the command with which it was started is remembered, so the subsequent
<code>docker container start will start the same process</code> with a
pseudo <code>tty</code>, then the
<code>docker container exec -it percy</code> bash will actually start
another bash process and attach to it. In the end one will end up with
two bash processes, running in this container, can be verified using the
docker top command. Note that <code>docker attach</code> will work for
<code>stdout</code> just fine, but if one wishes to attach to a running
process’ <code>stdin</code> that process would have to have been started
with the <code>-i flag</code></p>
<h4 id="cleaning-up">Cleaning up</h4>
<p>There is a quick and dirty way to remove all containers on the host
system, just to make sure that there are no left over resources,
similarly to how we did for the images, one can also destroy and remove
all containers, however that is not terminating them safely, meaning
that it should be used with caution. The following command can be used
to kill all containers</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># remove all containers, listed with ls -aq, the -f flag stands for force, which means it will kill all running</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># containers, regardless of their state</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container rm <span class="va">$(</span><span class="ex">docker</span> container ls <span class="at">-aq</span><span class="va">)</span> <span class="at">-f</span></span></code></pre></div>
<h2 id="containerizing-application">Containerizing application</h2>
<p>The process of taking an application and configuring i t to run as a
container is called containerizing, or dockerizing. The process is
somewhat simple</p>
<ol type="1">
<li>start with the application code</li>
<li>create a docker file that describes your app, its dependencies and
how to run it</li>
<li>feed this docker file into the docker image build command.</li>
<li>sit back while docker build your application into a docker
image.</li>
</ol>
<p>Once the image is created, i.e the app is containerized, you are
ready to ship and run it as a container.</p>
<h2 id="definition-2">Definition</h2>
<p>The process below explains in more detail and walks through all the
processes described above, for containerizing a Linux based nodejs web
app. The process is the same for Windows. The process includes, getting
the app code, inspect the docker file, containerize the app, run the
app, test the app.</p>
<h3 id="getting-the-code">Getting the code</h3>
<p>Let us assume that we already have the code, or we can clone a
repository which contain the code. Assume that this is a regular nodejs
project, which contains all the source files inside a folder called src,
located inside the top level project folder.</p>
<h3 id="building-the-docker-file">Building the docker file</h3>
<p>To build the docker file for our application, note that this docker
file does a few interesting things, one of them being that the code of
the application is copied inside the container, that is done during the
image build phase, meaning that the code of the app will be built into
the image. It is a common practice to keep the <code>Dockerfile</code>
at the root of the project’s folder, this way it is easier to refer to
resources from the project, in this case the resource that we are
interested in is the src folder, which contains the source of the
project.</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> alpine</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">LABEL</span> maintainer=<span class="st">&quot;nigelpoulton@hotmail.com&quot;</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">apk</span> add <span class="at">--update</span> nodejs nodejs-npm</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> . /src</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="kw">WORKDIR</span> /src</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">npm</span> install</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="kw">EXPOSE</span> 8080</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;node&quot;</span>, <span class="st">&quot;./app.js&quot;</span>]</span></code></pre></div>
<p>The <code>Dockerfile</code> also has a very important role which is
to bridge the gap between the dev and the ops, which means that it can
often be used to document the way a given application is supposed to be
bundled and distributed, built and tested. Which is quite important.</p>
<p><code>Dockerfile</code> starts with the FROM instruction. This will
be the base layer of the image, and the rest of the app will be added on
top as additional layers, this particular app is a Linux app, so it is
important that the FROM instruction refers to a Linux based image. If
you are containerizing a Windows app you will need to specify the
appropriate Windows base image.</p>
<p>Next is the LABEL and it specifies the maintainer of the image,
Labels are simple key value pairs and are an excellent way of adding
custom metatadata to an image, It is considered a best practice to list
a maintainer of an image so that other people and potential users have a
point of contact when working with it.</p>
<p>The RUN layer instructs the package manager to install nodejs and
nodejs-npm into the image. The RUN instruction installs. The instruction
installs these packages as a new image layer on top of the alpine base
image created by the FROM alpine instruction</p>
<p>The COPY instruction copies in the app files from the build context
the run instruction copies these files into the image as a new layer,
the image now has three layers</p>
<p>Next the <code>Dockerfile</code> uses the <code>WORKDIR</code>
instruction to set the working directory for the rest of the
instructions in the file. This directory is relative to the image, and
the information is added as metadata to the image config and not as a
new layer.</p>
<p>Then the RUN npm install instruction uses npm to install application
dependencies listed in npm package.json. It runs within the context of
the <code>WORKDIR</code> set in the previous instruction and installs
the dependencies as a new layer in the image.</p>
<p>The image now has four layers</p>
<ul>
<li>RUN npm install</li>
<li>COPY . /src</li>
<li>RUN apk add npm</li>
<li>FROM alpine</li>
</ul>
<p>The application exposes a web service on TCP port 8080 so the
<code>Dockerfile</code> documents this with the EXPOSE 8080 instruction.
This is added as image metadata and not an image layer. Finally the
<code>ENTRYPOINT</code> instruction is used to set the main application
that the image (container) should run. This is also added as metadata
and not an image layer.</p>
<h3 id="containerize-the-app-and-build-the-image">Containerize the app
and build the image</h3>
<p>Now that the application code and the <code>Dockerfiles</code> are
ready the image is ready to be built. The following command will make
sure to build a new image called web:latest. The period at the end of he
command tells Docker to use the shell’s current working directory as the
build context, in other words it tells the docker CLI where to find the
<code>Dockerfile</code> to use to build the image, in this case it is
run from the current working directory where the <code>Dockerfile</code>
is already located, therefore it is reasonable to use the
<code>cwd - current working directory</code></p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image build <span class="at">-t</span> web:latest .</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Sending</span> build context to Docker daemon 74.75kB</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Step</span> 1/8 : FROM alpine</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="ex">latest:</span> Pulling from library/alpine</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="ex">88286f41530e:</span> Pull complete</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="ex">Digest:</span> sha256:f006ecbb8...d935c0c103f4820a417d</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="ex">Status:</span> Downloaded newer image for alpine:latest</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="ex">---</span><span class="op">&gt;</span> 76da55c8019d</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>Snip<span class="op">&gt;</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="ex">Step</span> 8/8 : ENTRYPOINT node ./app.js</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="ex">---</span><span class="op">&gt;</span> Running in c576be4427a7</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="ex">---</span><span class="op">&gt;</span> e33cdd8266d0</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="ex">Removing</span> intermediate container c576be4427a7</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="ex">Successfully</span> built e33cdd8266d0</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="ex">Successfully</span> tagged web:latest</span></code></pre></div>
<p>After the command finishes one can also verify that the build has
been successfully by running the docker image ls command to verify that
the new image is added to the local registry as well.</p>
<h3 id="running-the-app">Running the app</h3>
<p>The example application that we have containerized is a simple web
server that listens on TCP port 8080. The following command will start a
new container called <code>c1</code> based on the web:latest image we
just created. It maps port 80 on the Docker host to port 8080 inside the
container. This mean that you will be able to point a web browser at the
DNS name or IP address of the Docker host and access the app.</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># run the container in the background with -d, give it a simple name and expose the port 8080 from the container to port 80 on the host.</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container run <span class="at">-d</span> <span class="at">--name</span> c1 <span class="at">-p</span> 80:8080 web:latest</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># check what is the status of the container after the command above has finished</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> container ls</span></code></pre></div>
<h3 id="test-connectivity">Test connectivity</h3>
<p>To test if everything is working fine, open up a web browser and
navigate to and pint it to the DNS name or IP address of the host that
the container is running on, this is usually
<code>localhost or 127.0.0.1</code></p>
<h2 id="closer-look">Closer look</h2>
<p>Now that the application is containerized let us take a closer look
at how some the machinery works, comment lines in a
<code>Dockerfile</code> start with # character. All non comment lines
are Instructions, Instructions take the format INSTRUCTION argument.
Instruction names are not case sensitive but it is normal practice to
write them in UPPERCASE. This makes reading the <code>Dockerfile</code>
easier. The docker image build command parses the
<code>Dockerfile</code> one line at a time starting from the top. Some
instructions create new layers, whereas others just add metadata to the
image. Examples of instructions that create new layers are FROM, RUN and
COPY. Examples of instructions that create metadata are
<code>EXPOSEEXPOSE</code>, <code>WORKDIR</code>, <code>ENV</code> and
<code>ENTRYPOINT</code>. The basic premise is that - if an instruction
is adding content such as files and programs to the image, it will
create a new layer, if it is adding instructions on how to build the
image and run the application it will create metadata. You can view the
instructions that were used to build the image with the docker image
history command.</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image history web:latest</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="ex">IMAGE</span>     CREATED BY                                           SIZE</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="ex">e33..6d0</span>  /bin/sh <span class="at">-c</span> <span class="co">#(nop) ENTRYPOINT [&quot;node&quot;./a...           0B</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="ex">d38..20c</span>  /bin/sh <span class="at">-c</span> <span class="co">#(nop) EXPOSE     8080/tcp                0B</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="ex">e2a..0b6</span>  /bin/sh <span class="at">-c</span> npm    install                            18.7MB</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="ex">a8e..50e</span>  /bin/sh <span class="at">-c</span> <span class="co">#(nop) WORKDIR    /src                    0B</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="ex">23b..b58</span>  /bin/sh <span class="at">-c</span> <span class="co">#(nop) COPY       dir:03b6808e26dacac...  22kB</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="ex">fda..b35</span>  /bin/sh <span class="at">-c</span> apk add <span class="at">--update</span> nodejs  nodejs-npm       32.9MB</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="ex">8d3..501</span>  /bin/sh <span class="at">-c</span> <span class="co">#(nop) LABEL      maintainer=nigelp...    0B</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="ex">76d..19d</span>  /bin/sh <span class="at">-c</span> <span class="co">#(nop) CMD        [&quot;/bin/sh&quot;]             0B</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>missing<span class="op">&gt;</span> /bin/sh <span class="ex">-c</span> <span class="co">#(nop) ADD        file:4583e12bf5caec4... 3.97MB</span></span></code></pre></div>
<p>Two things from this output above are worth noting. First each line
in the output corresponds to an instruction in the
<code>Dockerfile</code>, the created by column even lists the exact
instruction that was executed, second only 4 of the image layers are
displayed in the output contain any data (the ones with non-zero values
in the size columns) These correspond to the from, run and copy
instructions in the <code>Dockerfile</code>. Although the other
instructions look like they create layers, they only create metadata,
but are still listed.</p>
<p>Use the docker image inspect command to confirm that only 4 layers
were created.</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> image inspect web:latest</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>Snip<span class="op">&gt;</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;RootFS&quot;</span><span class="ex">:</span> {</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Type&quot;</span><span class="ex">:</span> <span class="st">&quot;layers&quot;</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Layers&quot;</span><span class="ex">:</span> [</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;sha256:5bef08...00324f75e56f589aedb0&quot;</span><span class="ex">,</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;sha256:03f8d2...f7061341ab09fab9d2d5&quot;</span><span class="ex">,</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;sha256:7bb5e2...5718961a7a706c5d0085&quot;</span><span class="ex">,</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">&quot;sha256:110b48...541f301505b0da017b34&quot;</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="ex">]</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>   <span class="er">}</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>Snip<span class="op">&gt;</span></span></code></pre></div>
<p>It is considered a good practice to use images from the official
repositories with the from instruction. This is because they tend to
follow best practices and be relatively free from known vulnerabilities.
It is also a good idea to start with a FROM small images as this reduces
the potential attack surface.</p>
<h2 id="moving-to-production">Moving to production</h2>
<p>When it comes to docker images, big is bad, big means slow, big means
hard to work with and big means a large attach surface, for these
reasons, Docker images should be small, the aim of the game is to only
ship production images containing the stuff needed to run your app in
production, The problem is keeping images small was hard work. For
example the way you write your <code>Dockerfiles</code> has a huge
impact on the size of the image. A common example is that every RUN
instruction adds a new layer. As a result it is usually considered a
best practice to include multiple commands as part of a single RUN
instruction - all glued together with double ampersands (&amp;&amp;) and
backslash for mutliline command break.</p>
<p>Another issues is that we do not clean up after ourselves, we RUN a
command against an image that pulls some build time tools and we leave
those tools in the image when we ship it to production - not good. There
are ways around this, most notably the builder pattern, but most require
a discipline and added complexity.</p>
<p>The builder pattern required you to have at least two
<code>Dockerfiles</code> one for development and one for production,
you’d write your <code>Dockerfile.dev</code> to start from a large base
image, pull in any additional build tools required and build your app,
you’d then build an image from the <code>Dockerfile.dev</code> and
create a container from it. You’d then use your
<code>Dockerfile.prod</code> to build a new image from a smaller base
image and copy over the application from the container</p>
<p>This approach was doable but at the expense of complexity, multi
stage builds to the rescue. Multi-stage builds are all about optimizing
builds without adding complexity. With multi stage builds we have a
single <code>Dockerfile</code> containing multiple FROM instructions.
Each FROM instruction is a new build stage that can easily copy
artifacts from previous stages.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode dockerfile"><code class="sourceCode dockerfile"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> node:latest <span class="kw">AS</span> storefront</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">WORKDIR</span> /usr/src/atsea/app/react-app</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> react-app .</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">npm</span> install</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">npm</span> run build</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> maven:latest <span class="kw">AS</span> appserver</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="kw">WORKDIR</span> /usr/src/atsea</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> pom.xml .</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">mvn</span> <span class="at">-B</span> <span class="at">-f</span> pom.xml <span class="at">-s</span> /usr/share/maven/ref/settings-docker.xml dependency<span class="dt">\</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>:resolve</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> . .</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">mvn</span> <span class="at">-B</span> <span class="at">-s</span> /usr/share/maven/ref/settings-docker.xml package <span class="at">-DskipTests</span></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="kw">FROM</span> java:8-jdk-alpine <span class="kw">AS</span> production</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="kw">RUN</span> <span class="ex">adduser</span> <span class="at">-Dh</span> /home/gordon gordon</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="kw">WORKDIR</span> /static</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> <span class="op">--from=storefront</span> /usr/src/atsea/app/react-app/build/ .</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a><span class="kw">WORKDIR</span> /app</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a><span class="kw">COPY</span> <span class="op">--from=appserver</span> /usr/src/atsea/target/AtSea-0.0.1-SNAPSHOT.jar .</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a><span class="kw">ENTRYPOINT</span> [<span class="st">&quot;java&quot;</span>, <span class="st">&quot;-jar&quot;</span>, <span class="st">&quot;/app/AtSea-0.0.1-SNAPSHOT.jar&quot;</span>]</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="kw">CMD</span> [<span class="st">&quot;--spring.profiles.active=postgres&quot;</span>]</span></code></pre></div>
<p>The first thing to note is that the <code>Dockerfile</code> above has
three FROM instructions, each of these constitutes a distinct build
stage, internally they are numbered from the top starting at 0, however
we have also given each stage a friendly name. Stage 0 is called
<code>storefront</code>, stage 1 is called <code>appserver</code>, stage
2 is called <code>production</code></p>
<p>The storefront stage pulls the node:latest image which is over
<code>600mb</code> in size. It sets the working directory copies in some
app code and uses two RUN instructions to perform some npm magic. This
adds three layers and considerable size. The result is an even bigger
image containing lots of build stuff and not very much app code.</p>
<p>The <code>appserver</code> stage pulls the maven latest image which
is over <code>700mb</code> in size, It adds four layers of content via
two copy instructions and two run instructions. This produces another
very large image with lots of build tools and very little actual
production code.</p>
<p>The production stage starts by pulling the java:8-jdk, This image is
approximately <code>150mb</code> - considerably smaller than the other
two stages. It adds in a user, sets the working directory and copies in
some app code from the image produced by the storefront stage. After
that it sets a different working directory and copies in the application
code from the image produced by the <code>appserver</code> stage.
Finally it sets the main application for the image to run when it is
started as a container.</p>
<p>The important things to note are that he <code>COPY --from</code>
instructions only copy production related application binaries from the
images built by the previous stages. They do not copy any other
auxiliary resources used to build the application itself, including the
code since those are not needed. Also note that the previous FROM/stages
instructions create images as well, which can be listed with
<code>docker image ls -a</code></p>
<h1 id="swarm-mode">Swarm mode</h1>
<p>At a high level orchestration is all about automating and simplifying
the management of containerized applications at a scale. Things like
automatically rescheduling containers when nodes break, scaling things
up when demand increases and smoothly pushing updates and fixes into
production environments. For the longest time orchestration like this
was hard, tools like <code>Docker Swarm</code> and
<code>Kubernetes</code> were available but they were complicated, then
along came Docker 1.12 and the new native swarm mode, and overnight
things changed. All the orchestration stuff got a whole lot easier.</p>
<h2 id="definition-3">Definition</h2>
<p>Swarm mode brought a load of changes and improvements to the way we
manage containers at scale. At the heart of those changes is native
clustering of Docker hosts that is deeply integrated into the Docker
platform. We are not talking about something like
<code>Kubernetes</code> that is separate too requiring a highly skilled
specialist to configure it on top of existing Docker infrastructure. The
clustering here is about first class citizen in the Docker technology
stack. And it is simple.</p>
<p>By default a standard installation of Docker will default to running
in single engine mode, ensuring 100% backward compatibility with
previous version of Docker. Putting Docker Engine into swarm mode gives
you all of the latest orchestration goodness it just comes in at the
price of some backward compatibility</p>
<h2 id="swarm">Swarm</h2>
<p>A swarm consist of one or more nodes. These can be physical servers,
virtual machines or cloud instances, the only requirement is that all
nodes in a swarm can communicate with each other over reliable networks.
Nodes are then configured as managers or workers. Mangers look after the
state of the cluster and are in charge of dispatching tasks/containers
to workers. Workers accept tasks from mangers and execute them. Swarm
nodes also heavily use and rely on <code>TLS</code> to encrypt
communications, authenticate nodes and authorize roles, Automatic key
rotation is also thrown in.</p>
<p>Locally when running docker swarm the node behavior of standalone
physical servers or virtual machine is simulated by the docker engine.
Therefore locally there is no real benefit of working with docker swarm,
since the power of the swarm is in the distributed nature of it across
many physical machines - each of which is a node. Another important
thing to note is that a single node can run many tasks or containers
inside of it, each node has its own docker engine and docker daemon and
so on.</p>
<h3 id="tasks">Tasks</h3>
<p>Tasks in the context of a swarm we mean containers, so when we say
managers dispatch tasks to workers we are saying they dispatch container
workloads, you might also hear them referred to as replicas this might
be confusing at this point so try and remember that tasks and replicas
are words that mean containers.</p>
<h3 id="enabling">Enabling</h3>
<p>To enable docker swarm, one needs to run the following command on the
docker host - <code>docker swarm init</code>. Docker host in
single-engine will now convert and switch to swarm mode. It will also
make the node the first manager of the Swarm. Additional nodes can then
be joined to the swarm as workers and managers using the
<code>docker swarm join</code> command.</p>
<h4 id="initializing">Initializing</h4>
<div class="sourceCode" id="cb26"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to switch the docker daemon host to a swarm mode instead of the default single node mode</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> swarm init</span></code></pre></div>
<p>The following steps will put <code>mgr1</code> into swarm mode and
initialize a new swarm. It will then join <code>wrk1</code> and
<code>wrk2</code> and <code>wrk3</code> as worker nodes - automatically
putting them int swarm mode. Finally it will add <code>mgr2</code> and
<code>mgr3</code> as additional managers and switch them into swarm
mode. At the end of the procedure all 6 nodes will be part of the same
swarm and will all be operating in swarm mode.</p>
<p>The current single local host becomes the cluster’s manager and is
responsible for maintaining the swarm state. While you only have one
physical machine, docker uses its own daemon and networking layers to
act as if you are running separate nodes.</p>
<h4 id="initializing-1">Initializing</h4>
<div class="sourceCode" id="cb27"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to initialize mgr1 into swarm mode and create a new swarm, with explicit IP addresses</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> swarm init <span class="at">--advertise-addr</span> 10.0.0.1:2377 <span class="at">--listen-addr</span> 10.0.1:2377</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="ex">Swarm</span> initialized: current node <span class="er">(</span><span class="ex">d21lyz...c79qzkx</span><span class="kw">)</span> <span class="ex">is</span> now a manager.</span></code></pre></div>
<p>This command can be broken down as follows</p>
<ul>
<li><p><code>docker swarm init</code> tells Docker daemon to initialize
a new swarm and make this node the first manager. It also enables the
swarm mode on the node.</p></li>
<li><p><code>advertise-addr</code> is the IP and port that other nodes
should use to connect to this manager. The flag is optional but it gives
you control over which IP gets used on nodes with multiple IPs. It also
gives you the chance to specify an IP address that does not exit on the
node such as a load balancing IP address.</p></li>
<li><p><code>listen-addr</code> lets you specify which IP and port you
want to listen on for swarm traffic. This will usually match the address
provided in <code>advertise-addr</code>, but is useful in situations
where you want to restrict swarm to a particular IP on a system</p></li>
</ul>
<h4 id="extending">Extending</h4>
<div class="sourceCode" id="cb28"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> swarm join-token worker</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="ex">To</span> add a manager to this swarm, run the following command: docker swarm join <span class="at">--token</span> SWMTKN-1-0uahebax...c87tu8dx2c 10.0.0.1:2377</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> swarm join-token manager</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="ex">To</span> add a manager to this swarm, run the following command: docker swarm join <span class="at">--token</span> SWMTKN-1-0uahebax...ue4hv6ps3p 10.0.0.1:2377</span></code></pre></div>
<p>Notice that the commands to join a worker and a manager are identical
apart from the join tokens (<code>SWMTKN</code> ending in either
<code>c87tu8dx2c</code> or <code>ue4hv6ps3p</code>). This means that
whether a node joins as a worker or a manager depends entirely on which
token you use when joining it. These tokens should be protected, as
these are all that is required to join a node to a swarm.</p>
<h4 id="adding-worker">Adding worker</h4>
<div class="sourceCode" id="cb29"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> swarm join <span class="at">--token</span> SWMTKN-1-0uahebax...c87tu8dx2c 10.0.0.1:2377</span></code></pre></div>
<p>To add <code>wrk1</code> and join it to the swarm using the docker
swarm join command with the correct token for a worker node
(<code>c87tu8dx2c</code>). Note that one can keep retrieving tokens for
a manager with the docker swarm join-token worker, this would produce a
new unique token which can be used to add a new worker to the swarm</p>
<h4 id="adding-manager">Adding manager</h4>
<div class="sourceCode" id="cb30"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> swarm join <span class="at">--token</span> SWMTKN-1-0uahebax...ue4hv6ps3p 10.0.0.1:2377</span></code></pre></div>
<p>To add <code>mgr1</code> and join in to the swarm using the docker
swarm join command with the correct token for a manager
(<code>ue4hv6ps3p</code>). Note that one can keep retrieving tokens for
a manager with the docker swarm join-token manager, this would produce a
new unique token which can be used to add a new manager to the swarm</p>
<h4 id="listing">Listing</h4>
<div class="sourceCode" id="cb31"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to list the nodes in the swarm</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> node ls</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="ex">ID</span>         HOSTNAME STATUS AVAILABILITY MANAGER STATUS</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="ex">d21...qzkx</span> mgr1     Ready  Active       Leader</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="ex">d21...qzkx</span> wrk1     Ready  Active</span></code></pre></div>
<p>This command will show that <code>mgr1</code> is currently the only
manager node in the swarm and the <code>wrk1</code> as the only worker
the swarm, but that depends on how many of the swarm join-token
worker/manager we run.</p>
<p>Looking at the manager status column in the list output, note that
only one manager can be <code>Leader</code>, the other managers will be
marked as <code>Reachable</code>. The worker nodes have no manager
status which should be obvious as to why.</p>
<h4 id="high-availability">High availability</h4>
<p>Swarm managers have native support for high availability (H/A). This
means that one or more can fail and the survivors will keep the swarm
running. Technically speaking, swarm mode implements a form of active
passive multi manager high availability. This means that although you
might and should have multiple managers, only one of them is ever
considered active. We call this active manager the leader. And the
leader is the only one that will ever issues live commands against the
swarm such as changing the configuration of the swarm or issuing tasks
to workers. If a non active manager receives commands for the swarm it
will proxy them across to the leader. The swarm uses and implementation
of the Raft consensus algorithm to power the high availability and the
following two best practices apply</p>
<ol type="1">
<li>Deploy an odd number of managers to avoid consensus collisions</li>
<li>Do not deploy too many managers (at best 3 or 5 is recommended)</li>
</ol>
<p>Having an odd number of managers increases the change of reaching
quorum and avoiding a split-brain. Fr example if you had 4 managers and
the network partitioned you could be left with two mangers on each side
of the partition. This is known as a split brain - each side knows there
used to be 4 but can now only see 2. Neither side has any way of knowing
if the two it can no longer see are still alive and which side holds the
majority share (quorum). However if you had 3 or 5 managers and the same
network partition occurred it would be impossible to have the same
number of managers on both sides of the split. This means that one side
would have a far better chance of knowing if it had more or less than
the other side and achieving quorum. As with all consensus algorithms
more participants means more time required to achieve consensus, it is
like deciding where to eat - it is quicker and easier for 3 people to
decide than it is for 33.</p>
<p>A final word of caution regarding manager HA. While it is obviously a
good practice to spread your managers across availability zones within
your network you need to make sure that the networks connecting them are
reliable. Network partitions can be a pain. This means hosting your
active production applications and infrastructure across multiple cloud
providers such as AWS or Azure is a bit of a daydream.</p>
<h3 id="service">Service</h3>
<p>Services, at the highest level services are the way to run tasks on a
swarm to run a task/container on a Swarm we wrap it in a service and
deploy that service. Beneath the hood service are declarative way of
setting the desired state on the cluster. For example</p>
<ul>
<li>set the number tasks/containers in the service</li>
<li>set the image the containers in the service will use</li>
<li>set the procedure for updating to newer version of the image</li>
</ul>
<p>Services let us declare the desired state for an application service
and feed that to Docker. For example assume that you have got an app
that has a web front end. You have an image for the web service and
testing has shown that you will need 5 instance of the web service. You
would translate the requirement into a service declaring the image the
containers should use, and that service should always have 5 running
tasks. To create a service use the <code>docker service create</code>
command</p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service create <span class="at">--name</span> web-fe <span class="at">-p</span> 8080:8080 <span class="at">--replicas</span> 5 nigelpoulton/pluralsight-docker-ci</span></code></pre></div>
<p>The name flag tells docker what name to assign to the service, also
docker is told to map port 8080 on every node in the swarm to 8080
inside of each container (task) in the service. Next the replicas flag
to tell Docker that there should always be 5 tasks or containers running
in the service. Finally Docker is told which image to use in this case
it is an example custom image representing the app -
<code>nigelpoulton/pluralsight/docker-ci</code>.</p>
<p>After executing the command the manager acting as a leader
instantiated 5 tasks across the swarm, remember that managers also act
as workers. Each worker or manager then pulled the image and started a
container from it running on port 8080. The swarm leader also ensured a
copy of the service desired state was replicated to every manager in the
swarm.</p>
<p>All services are constantly monitored by the swarm, the swarm runs a
reconciliation loop the constantly compares the actual state of the
service to the desired state, if the two states match the world is a
happy place, and no further actions is needed, if they do not match the
swarm takes actions so that they do. Or in other words the swarm is
constantly making sure that the actual state matches the desired state,
on a constant loop.</p>
<p>As an example if one of the workers hosting one of the 5 containers
tasks fails the actual state for the <code>web-fe</code> service will
drop from 5 running tasks to 4, this will no longer match the desired
state of 5, so Docker will start a new <code>web-fe</code> task to bring
actual state back in line with the desired state. This behavior is very
powerful and allows the service to self-heal in the event of node
failures and the likes.</p>
<p>Listing service can be done with the command
<code>docker service ls</code>. This will show all services, and their
details</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service ls</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="ex">ID</span>       NAME   MODE       REPLICAS IMAGE             PORTS</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="ex">z7o...uw</span> web-fe replicated 5/5      nigel...ci:latest <span class="pp">*</span>:8080-<span class="op">&gt;</span>8080</span></code></pre></div>
<p>The output shows a single running service as well as some basic
information about the state. Among other things we can see that the name
of the service and that 5 out of the 5 desired tasks/replicas/container
instances are in running state, If one runs the command soon after
deploying the service it might not show all tasks or replicas as
running, this is probably because of the time it takes to pull the image
on each node.</p>
<p>The <code>docker service ps</code> command can be used to see a list
of tasks in a service and their state, this is similar to the PS command
on Linux or Unix which shows information about the current processes
running on the system.</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service ps <span class="op">&lt;</span>service-name<span class="op">&gt;</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a><span class="ex">ID</span>        NAME     IMAGE            NODE DESIRED CURRENT</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="ex">817...f6z</span> web-fe.1 nigelpoulton/... mgr2 Running Running 2 mins</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="ex">a1d...mzn</span> web-fe.2 nigelpoulton/... wrk1 Running Running 2 mins</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="ex">cc0...ar0</span> web-fe.3 nigelpoulton/... wrk2 Running Running 2 mins</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="ex">6f0...azu</span> web-fe.4 nigelpoulton/... mgr3 Running Running 2 mins</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="ex">dyl...p3e</span> web-fe.5 nigelpoulton/... mgr1 Running Running 2 mins</span></code></pre></div>
<p>For a more detailed information about a service use the docker
service inspect command. This will show a more concise stack of
information</p>
<div class="sourceCode" id="cb35"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> servie inspect <span class="at">--pretty</span> <span class="op">&lt;</span>service-name<span class="op">&gt;</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="ex">ID:</span> z7ovearqmruwk0u2vc5o7ql0p</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="ex">Name:</span> web-fe</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="ex">Service</span> Mode: Replicated</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="ex">Replicas:</span> 5</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="ex">Placement:</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="ex">UpdateConfig:</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="ex">Parallelism:</span> 1</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="ex">On</span> failure: pause</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a><span class="ex">Monitoring</span> Period: 5s</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="ex">Max</span> failure ratio: 0</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="ex">Update</span> order: stop-first</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="ex">RollbackConfig:</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="ex">Parallelism:</span> 1</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="ex">On</span> failure: pause</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="ex">Monitoring</span> Period: 5s</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="ex">Max</span> failure ratio: 0</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="ex">Rollback</span> order: stop-first</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="ex">ContainerSpec:</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="ex">Image:</span> nigelpoulton/pluralsight-docker-ci:latest@sha256:7a6b01...d8d3d</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="ex">Resources:</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="ex">Endpoint</span> Mode: vip</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="ex">Ports:</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="ex">PublishedPort</span> = 8080</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="ex">Protocol</span> = tcp</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a><span class="ex">TargetPort</span> = 8080</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="ex">PublishMode</span> = ingress</span></code></pre></div>
<p>The example above uses the –pretty flag to limit the output to the
most interesting items printed in an easy to read format. Leaving off
the –pretty flag will give a more verbose output.</p>
<h4 id="scaling">Scaling</h4>
<p>Another powerful feature of services is the ability to easily scale
them up and down. Let us assume business is booming and we are seeing
double the amount of anticipated traffic hitting the
<code>webfront</code> end. Fortunately scaling the service is as simple
as running the docker service scale command</p>
<div class="sourceCode" id="cb36"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># scale the service from 5 to 10 replicas</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service scale <span class="op">&lt;</span>service-name<span class="op">&gt;</span>=10</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="op">&lt;</span>service-name<span class="op">&gt;</span> scaled <span class="ex">to</span> 10</span></code></pre></div>
<p>Running a docker service <code>ps</code> command will now show that
the tasks i the service are balanced across all nodes in the swarm as
evenly as possible. That means that given the fact that we have less
worker and manager nodes, there is no way to run one replica per worker
or manager, meaning that they will be distributed across the workers and
mangers, therefore one worker might get 2 or even 3 tasks running on
them, depending on how the docker engine and the swarm splits them up,
it is not something that we have control over generally.</p>
<p>Behind the scenes swarm mode runs a scheduling algorithm that
defaults to trying to balance tasks as evenly as possible across the
nodes in the swarm. This amounts to running an equal number of tasks on
each node without taking into consideration things like CPU load
etc.</p>
<p>To reduce the number of replicas, one can run the same command again,
doing <code>docker service scale &lt;service-name&gt;=5</code>, which
will scale down the service back to 5, the initial desired state, this
will remove running tasks from the worker and managers, again no control
over which exact instances are killed, which is fine since they are all
clones of each other anyway</p>
<h4 id="removing-1">Removing</h4>
<p>To remove or delete a service is simple, as simple as running docker
service rm <service-name>. This will delete the service we have already
deployed earlier. However a word of caution when using the docker
service rm command as is, it deletes all tasks in the service without
asking for confirmation, meaning that along with the service, all
running tasks will be killed/stopped from running on the nodes in the
swarm</p>
<h4 id="updating">Updating</h4>
<p>Pushing updates to deployed application is a fact of life. And for
the longest time it has been really painful, we have lost more than
enough weekends to major application updates. To demonstrate how this
works, the example below is using the rolling update method, but any
number of other methods can be employed, however docker does provide a
rolling update method out of the box,
<code>with the use of update-parallelism &amp; update-delay</code></p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create an overlay network, an overlay network essentially creates a new layer 2 network that can be used to place</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="co"># containers on and these containers can all communicate with each other, this works even if the Docker hosts they are</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="co"># running on are on different underlying networks</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> network create <span class="at">-d</span> overlay uber-net</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to list the available networks on the docker host, note that some of these might look familiar like the bridge, host,</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="co"># and none, also the last column shows what is the type of the network, where does it run - local implies that it is</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># running on the local docker engine host, while swarm implies it is part of the swarm</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="ex">$</span> docker network ls</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a><span class="ex">NETWORK</span>      ID              NAME    DRIVER SCOPE</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="ex">490e2496e06b</span> bridge          bridge  local</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="ex">a0559dd7bb08</span> docker_gwbridge bridge  local</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a><span class="ex">a856a8ad9930</span> host            host    local</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="ex">1ailuc6rgcnr</span> ingress         overlay swarm</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a><span class="ex">be581cd6de9b</span> none            null    local</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a><span class="ex">43wfp6pzea47</span> uber-net        overlay swarm</span></code></pre></div>
<div class="sourceCode" id="cb39"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the new service which is going to be used for demo purposes for rolling updates on the app</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service create <span class="at">--name</span> uber-svc <span class="at">--network</span> uber-net <span class="at">-p</span> 80:80 <span class="at">--replicas</span> 12 nigelpoulton/tu-demo:v1</span></code></pre></div>
<div class="sourceCode" id="cb40"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># list the current services, which are active</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service ls</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="ex">ID</span>           NAME        REPLICAS            IMAGE</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="ex">dhbtgvqrg2q4</span> uber-svc    12/12               nigelpoulton/tu-demo:v1</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="co"># list all the tasks/containers/replicas for the service</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service ps uber-svc</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="ex">ID</span>           NAME        IMAGE               NODE DESIRED CURRENT STATE</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="ex">0v...7e5</span>     uber-svc.1  nigelpoulton/...:v1 wrk3 Running Running 1 min</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="ex">bh...wa0</span>     uber-svc.2  nigelpoulton/...:v1 wrk2 Running Running 1 min</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="ex">23...u97</span>     uber-svc.3  nigelpoulton/...:v1 wrk2 Running Running 1 min</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="ex">82...5y1</span>     uber-svc.4  nigelpoulton/...:v1 mgr2 Running Running 1 min</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="ex">c3...gny</span>     uber-svc.5  nigelpoulton/...:v1 wrk3 Running Running 1 min</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="ex">e6...3u0</span>     uber-svc.6  nigelpoulton/...:v1 wrk1 Running Running 1 min</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a><span class="ex">78...r7z</span>     uber-svc.7  nigelpoulton/...:v1 wrk1 Running Running 1 min</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a><span class="ex">2m...kdz</span>     uber-svc.8  nigelpoulton/...:v1 mgr3 Running Running 1 min</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="ex">b9...k7w</span>     uber-svc.9  nigelpoulton/...:v1 mgr3 Running Running 1 min</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="ex">ag...v16</span>     uber-svc.10 nigelpoulton/...:v1 mgr2 Running Running 1 min</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="ex">e6...dfk</span>     uber-svc.11 nigelpoulton/...:v1 mgr1 Running Running 1 min</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="ex">e2...k1j</span>     uber-svc.12 nigelpoulton/...:v1 mgr1 Running Running 1 min</span></code></pre></div>
<div class="sourceCode" id="cb41"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># update the service with a new image, with a 20 second delay at a time, and 2 containers/tasks per update</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service update <span class="at">--image</span> nigelpoulton/tu-demo:v2 <span class="at">--update-parallelism</span> 2 <span class="at">--update-delay</span> 20s uber-svc</span></code></pre></div>
<p>What does this command really do ? Well the docker service update
lets us make updates to a running service, by updating the service’s
desired state, this time we gave it a new image tag <code>v2</code>,
instead of <code>v1</code>. And used the update-parallelism, and the
update-delay. What this does is that the new image was pushed to
<code>2 tasks at a time with a 20 second cool off</code> period in
between each pair. Running the <code>docker service ps</code> against
the service some of the tasks in the service are at <code>v2</code>
image, while some at <code>v1</code>.</p>
<div class="sourceCode" id="cb42"><pre
class="sourceCode sh"><code class="sourceCode bash"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="ex">docker</span> service ps uber-svc</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="ex">ID</span>       NAME         IMAGE      NODE DESIRED  CURRENT  STATE</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="ex">7z...nys</span> uber-svc.1   nigel...v2 mgr2 Running  Running  13 secs</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="ex">0v...7e5</span> <span class="dt">\_</span>uber-svc.1 nigel...v1 wrk3 Shutdown Shutdown 13 secs</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="ex">bh...wa0</span> uber-svc.2   nigel...v1 wrk2 Running  Running  1  min</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="ex">e3...gr2</span> uber-svc.3   nigel...v2 wrk2 Running  Running  13 secs</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="ex">23...u97</span> <span class="dt">\_</span>uber-svc.3 nigel...v1 wrk2 Shutdown Shutdown 13 secs</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="ex">82...5y1</span> uber-svc.4   nigel...v1 mgr2 Running  Running  1  min</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="ex">c3...gny</span> uber-svc.5   nigel...v1 wrk3 Running  Running  1  min</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="ex">e6...3u0</span> uber-svc.6   nigel...v1 wrk1 Running  Running  1  min</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="ex">78...r7z</span> uber-svc.7   nigel...v1 wrk1 Running  Running  1  min</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a><span class="ex">2m...kdz</span> uber-svc.8   nigel...v1 mgr3 Running  Running  1  min</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="ex">b9...k7w</span> uber-svc.9   nigel...v1 mgr3 Running  Running  1  min</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a><span class="ex">ag...v16</span> uber-svc.10  nigel...v1 mgr2 Running  Running  1  min</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="ex">e6...dfk</span> uber-svc.11  nigel...v1 mgr1 Running  Running  1  min</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a><span class="ex">e2...k1j</span> uber-svc.12  nigel...v1 mgr1 Running  Running  1  min</span></code></pre></div>
<h4 id="strategies">Strategies</h4>
<p>As we have seen above, this is one of the many deployment strategies
which we can take in order to update our service, however there are a
few other. Not all deployment strategies are listed below, however some
of the more well known ones are, along with their pros and cons
depending on the circumstances</p>
<ul>
<li><p>Recreate Target - stops the old version entirely before deploying
the new one, all instances of the app are replaced simultaneously. This
is simple to implement, and guarantees no coexistence of old and new
versions, no resource hogging. However there is a downtime during
deployment process, clients experience a complete service outage. This
is suitable for non critical apps where downtime is acceptable</p></li>
<li><p>Rolling Update - Gradually replaces old instances with new ones,
one or a few at a time, continues until all instances are updated. It
has minimal downtime, allows monitoring of new instances as they are
deployed and put into action, reduces deployment risk compared to an
all-at-once strategy. However old and new versions coexist during the
deployment which may cause inconsistencies, it also requires careful
planning for compatibility between versions. Common for stateless or
backward compatible apps</p></li>
<li><p>Blue-Green - Deploys the new version (green) alongside the
current version (blue) in parallel, traffic is switched to the new
version once it is verified to be working, the old version remains
available as a fallback. The cool thing here is that there is no
downtime, seamless transition for users, easy and fast rollback, since
the old version is still active and running. However resource intensive
since both the versions are working or active at the same time, complex
traffic routing needs to be setup in order to make this viable and
transparent to the end user.</p></li>
<li><p>Canary - deploys the new version to a small subset of users or
servers first, gradually increases the percentage of traffic routed to
the new version, full roll-out occurs after successful validation.
Allows controlled testing in production with minimal risk, issues can be
caught early and affect fewer users, rollbacks are easier during initial
stages. Requires dynamic traffic routing and monitoring systems, and
takes longer to fully deploy compared to the other strategies</p></li>
<li><p>Feature toggle - deploys the new version with features disabled,
features are enabled incrementally via configuration toggles without
redeploying the code. There is a minimal risk, features can be turned
off instantly if issues occur, allows gradual roll-out of new
functionality, supports A/B testing and phased roll-outs. However in
increases code complexity, as well as there is a risk of stale toggles
cluttering the codebase i.e obsolete features.</p></li>
<li><p>Shadow - deploys the new version alongside the old version but
does not expose it to users, the new version processes mirrored traffic
for testing purposes. No impact on live users, allows the real-world
testing of the new version, High resource usage, in effect you have two
production environments, and does not test user interactions with the
new versions, rather testers or QA do that, which is not really the
same</p></li>
<li><p>A/B Testing - deploys multiple versions at the same time - the
old and the new. Routes a subset of users to the new version while the
rest continue using the old version. Collects metrics to compare
performance and user experience. Provides direct insights into user
preferences, and performance of different versions, allows for
controlled exposure to the new version. However it requires robust
traffic routing and user segmentation, risk of user confusion if
versions behave differently. Requires a robust traffic routing and user
segmentation. Risk of user confusion if version behave
differently</p></li>
</ul>
<h1 id="networking">Networking</h1>
<p>In the real world, containers have to be able to communicate with
each other reliably and securely even when they are on different hosts,
on different networks. This is where overlay networking comes in to
play. It allows you to create a flat secure layer 2 network spanning
multiple hosts, that containers can connect to. Containers on this
network can then communicate directly. Behind the scenes the docker
networking stack is comprised of <code>libnetwork</code> and drivers.
<code>Libnetwork</code> is the canonical implementation of the container
network model (<code>CNM</code>) and drivers are pluggable components
that implement different networking technologies and topologies.</p>
<h2 id="definition-4">Definition</h2>
<p>In 2025 Docker, Inc acquired container networking startup Socket
Plane. Two of the reasons behind the acquisition were to bring real
networking to Docker and to make container networking simple.</p>
<h1 id="security">Security</h1>
<p>Good security is all about the layers, and docker has lots of layers,
it supports all the major Linux security technologies as well as having
a lot of its own, and most them are simple and easy to configure. Docker
on Linux leverages most of the common Linux security technologies, these
include
<code>namespaces, control groups, capabilities, mandatory access control and seccomp</code>.
For each docker implements sensible defaults for a seamless and
moderately secure out of the box experience. However it also allows you
to customize each one to your liking.</p>
<p>The Docker platform itself offers some excellent native security
technologies, and one the best things about these is that they are
amazingly simple to use.</p>
<ul>
<li><p>Docker Swarm mode is secure by default, you get all the following
with zero configuration required - cryptographic node ID, mutual
authentication, automatic CA configuration, automatic certificate
rotation, encrypted cluster store, encrypted networks.</p></li>
<li><p>Docker content trust lets yo sign your images and verify the
integrity and publisher of images you pull</p></li>
<li><p>Docker Security Scanning analyses Docker images, detects known
vulnerabilities and provides you with a detailed report.</p></li>
<li><p>Docker secrets - makes secrets first class citizens in the Docker
ecosystem, they get stored in the encrypted cluster store, encrypted in
flight when delivered to containers, and stored in in-memory filesystems
when in use</p></li>
</ul>
<h2 id="definition-5">Definition</h2>
<p>Linux security technologies, what are those ? All good container
platforms should use <code>namespaces</code> and cgroups to build
containers. The best container platforms will also integrate with other
Linux security technologies such as
<code>capabilities, mandatory access control systems and seccomp</code></p>
<h3 id="namespaces">Namespaces</h3>
<p>Kernel <code>namespaces</code> are at the very heart of containers,
they let us slice up an operating system so that it looks and feels like
multiple isolate operating systems, this lets us do really cool things
like run multiple web servers on the same OS without having port
conflicts, it also lets us run multiple apps on the same OS without them
fighting over shared configuration files and shared libraries.</p>
<ul>
<li><p>You can run multiple web servers, each requiring port 443 on a
single OS. To do this you jut run each web server app inside its own
network <code>namespace</code>.This works because each network
<code>namespace</code> gets its own IP address and full range of
ports.</p></li>
<li><p>You can run multiple apps each requiring their own particular
version of a shared library or configuration file. To do this you run
each app inside of its own mount namespace. This works because each
mount <code>namespace</code> can have its own isolated copy of any
directory on the system (/etc, /var, /dev etc.)</p></li>
</ul>
<p>Docker on Linux currently utilizes the following kernel types of
<code>namespaces</code>:</p>
<ul>
<li>Process id (pid)</li>
<li>Network (net)</li>
<li>Filesystem mount (mnt)</li>
<li>Inter-process communication (ipc)</li>
<li>User (user)</li>
<li>UTS</li>
</ul>
<p><code>A docker container is an organized collection of namespaces.</code>
For example every container is made up of its own
<code>pid, net, mnt, ipc, uts and potentially user namespaces</code>.
The organized collection of these is what we call a container.</p>
<ul>
<li><p>PID - <code>namespace</code> - docker uses the pid
<code>namespace</code> to provide isolated process trees for each
container, every container gets it own process tree meaning that every
container can have its own PID 1, PID <code>namespaces</code> also mean
that a container can not have see or access to the process tree of other
containers or host processes it’s running on</p></li>
<li><p>Network - docker uses the net <code>namespace</code> to provide
each container its own isolated network stack, this stack includes
interfaces, IP addresses, port ranges, and routing tables, for example
every container gets its own <code>eth0</code> interface with its own
unique IP and range of ports</p></li>
<li><p>Mount - every container gets its own unique isolate
<code>root/filetsystem</code>. This means that every container can have
its own <code>/etc, /var, /dev etc</code>. Processes inside of a
container cannot access the mount <code>namesapce</code> of the Linux
host, or other containers, they can only see and access their own
isolate mount <code>namespace</code>.</p></li>
<li><p>Inter process communication - docker uses the IPC
<code>namespace</code> for shared memory access within a container. It
also isolates the container from shared memory outside of the
container.</p></li>
<li><p>User - docker lets you use the user <code>namespace</code> to map
users inside of a container to a different user on the Linux host, a
common example would be mapping the root user of a container to a
non-root user on the Linux host, user <code>namespaces</code> are quite
new to Docker and are currently optional</p></li>
<li><p>UTS - docker uses the UTS <code>namespace</code> to provide each
container with its own <code>hostname</code>.</p></li>
</ul>
<h3 id="control-groups">Control groups</h3>
<p>If <code>namespaces</code> are about isolation, the control groups
are about setting limits, think of containers as similar to rooms in a
hotel, yes each room is isolated but each room also shares a common set
of resources, things like water supply electricity supply, shared
swimming pool shared gym shared breakfast bar etc. Control groups let us
set limits on containers so that no single container can use all of the
resources on the host</p>
<p>In the real world, containers are isolated from each other but all
share a common set of resources - things like the host processor, ram
and disk. Control groups let us set limits on each of these so that a
single container can not take ownership of the whole host system
resources</p>
<h3 id="capabilities-1">Capabilities</h3>
<p>It is a bad idea to run containers as root - root is all powerful and
therefore very dangerous but it is a pain in the backside running
containers as non-root, non root is so powerless it is practically
useless. What we need is a technology that lets us pick and choose which
root powers our containers need in in order to run. Under the hood the
Linux root account is made up of a long list of capabilities, some these
include</p>
<ul>
<li><code>CAP_SHOWN</code> - lets you change file ownership</li>
<li><code>CAP_NET_BIND_SERVICE</code> - lets you bind a socket to low
numbered network ports</li>
<li><code>CAP_SETUPID</code> - lets you elevate the privilege level of a
process</li>
<li><code>CAP_SYS_BOOT</code> - lets you reboot the system.</li>
</ul>
<p>Docker works with capabilities so that you can run containers as
root, but strip out the root capabilities that you do not need. For
example if the only root privilege your container needs is the ability
to bind to low numbered network ports yo should start a container and
drop all root capabilities then add back the
<code>CAP_NET_BIND_SERVICE</code> capability. Docker also imposes
restrictions so that containers cannot re-add the removed capabilities
back.</p>
<h3 id="mandatory-access-control-systems">Mandatory access control
systems</h3>
<p>Docker works with a major Linux MAC technologies such as
<code>AppArmor</code> and <code>SELinux</code>. Depending on your Linux
distribution, Docker applies a default <code>AppArmor</code> profile to
all new containers, According to the Docker documentation, this default
profile is moderately protective while providing wide application
compatibility, Docker also lets you start containers without a policy
applied as well as giving you the ability to customize policies to meet
your specific requirements.</p>
<h3 id="seccomp-1">Seccomp</h3>
<p>Docker uses <code>seccomp</code>, if filter mode, to limit the
<code>syscalls</code> a container can make to the host kernel. As per
the docker security philosophy all new containers get a default
<code>seccomp</code> profile configured with sensible defaults, this is
intended to provide a moderate security without impacting application
compatibility. As always you can customize <code>seccomp</code> profiles
and you can pass a flag to docker so that containers can be started
without a <code>seccomp</code> profile,</p>
<h2 id="conclusion">Conclusion</h2>
<p><code>Docker supports most of the important Linux security technologies and ships, with sensible defaults that add security but are not too restrictive. Some of these technologies can be complicated to customize as they can require deep dive knowledge of how they work and how the Linux kernel works, Hopefully they will get simpler to configure in the future but for now the default configurations that ship with Docker are a good place to start.</code></p>
<h2 id="swarm-security">Swarm security</h2>
<p>Swarm mod is the future of Docker, since it lets you cluster multiple
docker hosts (nodes) and deploy your app in a declarative way, Every
swarm is comprised of managers and workers, that can be Linux or
Windows, Managers make up the control plane of the cluster and are
responsible for configuring the cluster and dispatching work to it.
Workers are the nodes that run your application code as containers. As
expected, swarm mode includes many security features that are enabled
out of the box with a sensible defaults. These include</p>
<ul>
<li>Cryptographic node IDs</li>
<li>mutual authentication via TLS</li>
<li>secure join tokens</li>
<li>CA configuration with automatic certificate rotation</li>
<li>Encrypted cluster store (config DB)</li>
<li>Encrypted networks</li>
</ul>
<p>The moment the <code>docker swarm init</code> command is executed,
the default security configurations take place out of the box, with
sensible defaults as already mentioned, The swarm has been given a
cryptographic ID, and <code>mgr1</code> has issues itself with a client
certificate that identifies it as a manager in the Swarm. Certificate
rotation has been configured with the default value of 90 days and a
cluster configuration database has been configured and encrypted. A set
of secure tokens have also been created so that new managers and new
workers can be joined to the Swarm, and all of this with a single
command.</p>
<h2 id="swarm-join-tokens">Swarm join tokens</h2>
<p>The only thing that is needed to join managers and workers to an
existing swarm is the relevant join token. For this reason it is vital
that you keep your tokens safe, no posting them on public repositories.
Every swarm maintains two distinct join tokens - one for joining new
managers and one for joining new workers. It is worth understanding the
format of the Swarm join token, every join token is comprised of 4
distinct fields separated by dashes, the format looks like that -
<code>PREFIX - VERSION - SWARM ID - TOKEN</code>.</p>
<ul>
<li>The prefix is always - <code>SWMTKN</code>.</li>
<li>The version fields indicates the version of the Swarm</li>
<li>The Swarm ID field is a hash of the swarm’s certificate.</li>
<li>The token portion is the part that determines if the token can be
used to join node as manager or worker.</li>
</ul>
<p>If you suspect that either of your join tokens has been compromised
you can revoke them and issue new ones with a single command, the
following example revokes the existing manager join token and issues a
new one, <code>docker swarm join-token --rotate manager</code>. Notice
that the only difference between the old and new join tokens is going to
be in the last field, the swarm id remains the same. Join tokens are
stored in the cluster config database, which is encrypted by
default.</p>
<h2 id="tls-and-mutual-authentication">TLS and mutual
authentication</h2>
<p>Every manager and worker that joins a Swarm is issued a client
certificate, this certificate is used for mutual authentication, it
identifies the node, which Swarm the node is a member of, and role the
node performs in the Swarm (manger or worker). On a Linux host, one can
inspect a node’s client certificate with the following command -
<code>sudo openssl x509 -in /var/lib/docker/swarm/certificates/swarm-node.crt -text</code>.
That will decrypt the certificate, and display the contents of it in
human readable format.</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode txt"><code class="sourceCode default"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>Certificate:</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>Data:</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>Version: 3 (0x2)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>Serial Number:</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>80:2c:a7:b1:28...a8:af:89:a1:2a:51:89</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>Signature Algorithm: ecdsa-with-SHA256</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>Issuer: CN=swarm-ca</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>Validity</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>Not Before: Jul 19 07:56:00 2017 GMT</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>Not After : Oct 17 08:56:00 2017 GMT</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>Subject: O=mfbkgjm2tlametbnfqt2zid8x, OU=swarm-manager,</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>CN=7xamk8w3hz9q5kgr7xyge662z</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>Subject Public Key Info:</span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>&lt;SNIP&gt;</span></code></pre></div>
<p>The Subject data in the output above uses the standard
<code>O, OU, and CN</code> fields to specify the Swarm ID, the node’s
role and the node ID.</p>
<ul>
<li>The organization <code>O</code> field stores the Swarm ID</li>
<li>The organizational unit <code>OU</code> field stores the nodes role
in the Swarm</li>
<li>The canonical name <code>CN</code> field stores the nodes crypto
ID</li>
</ul>
<p>Some of the certificate properties can be configured, like for
example the rotation period with the following command
<code>docker warm update --cert-expiry 720h</code>, this will set the
expiration of the certificate to 30 days instead of the default 90.
Swarm allows nodes to renew certificates early, before they expire, so
that not all nodes in the Swarm try and update their certificates at the
same time. You can configure an external CA (signing authority) when
creating a Swarm by passing the <code>--external-ca</code> flag to the
<code>docker swarm init</code> command. The new docker swarm ca
sub-command can also be used to manage the CA related configuration. Run
the command with the <code>--help</code> flag to see the list of things
it can do</p>
<h2 id="cluster-store">Cluster store</h2>
<p>The cluster store is the brains of a Swarm and is the place where
cluster configuration and state are stored, the store is currently based
on an implementation of etcd and is automatically configured to
replicate itself to all managers in the Swarm, it is also encrypted by
default. The cluster store is becoming a critical component of many
docker platform technologies - for example Docker networking and Docker
secrets both use the cluster store. This is one of the reasons that</p>
<h2 id="signing-images">Signing images</h2>
<p>Docker content trust, makes it simple and easy to verify the
integrity and the publisher of images that you download, This is
especially important when pulling images over untrusted networks such as
the internet. At a high level the docker content trust allows developers
to sign their images when they are pushed to docker hub or docker
trusted registry, ti will also automatically verify images when they are
pulled. Docker content trust can also provide important context, this
includes things like whether an image has been superseded by a newer
version and is therefore stale.</p>
<h2 id="secrets">Secrets</h2>
<p>Many applications need secrets, things like passwords, certificates,
ssh keys and more. Docker introduced something called docker secrets,
effectively making secrets first class citizens in the docker ecosystem.
For example there is a whole new docker secret sub command dedicated to
managing secrets. There is also page for creating and managing secrets
in the <code>docker universal control plane ui</code>. Behind the scenes
secrets are encrypted at rest, encrypted in-flight, mounted in memory
<code>filesystems</code> and only available to services/containers that
have been explicitly granted access to them, it is quite a comprehensive
end to end solution</p>
<p>So how does this process work, imagine we have 3 worker, each of
which is running two different images - red and blue. The red and the
blue each have two replicas/tasks/containers active/running in the
service. One of the workers is running one instance of the red and one
instance of the blue (due to the fact that we have 3 workers, but 4
tasks in total, one of the workers is bound to have 2 tasks/containers
running on it, in this case one of each kind - red and blue). Now the
challenge here is how to distribute the secret to the workers, without
leaking the information to tasks/containers that must not see it.</p>
<div class="sourceCode" id="cb44"><pre
class="sourceCode txt"><code class="sourceCode default"></code></pre></div>
<ol type="1">
<li>The secret is created and posted to the Swarm</li>
<li>It gets stored in the encrypted cluster store</li>
<li>The blue service is created and the secret is attached to it</li>
<li>The secret is encrypted in flight while it is delivered to the
containers in the blue service</li>
<li>The secret is mounted into the containers of the blue service as an
unencrypted file /run/secrets/. This is an in memory tmpfs
filesystem.</li>
<li>Once the container service task completes the in memory filesystem
is torn down</li>
<li>The red containers service cannot access the secret.</li>
</ol>
</body>
</html>
