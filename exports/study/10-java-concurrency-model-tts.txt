Thread model

Concurrency is becoming increasingly important as multi-core processors become more common. The word concurrency comes from the Latin root meaning “running together.” In programming, concurrency allows multiple threads to run in parallel within a program, each executing different tasks at the same time. When used properly, concurrency can improve both the performance and responsiveness of an application, making it a powerful and valuable feature.

From its earliest versions, Java has supported concurrency through low-level thread management, locks, and synchronization. Starting with version five, Java introduced a high-level concurrency API in the concurrent package. With version eight, Java’s support for concurrency improved further, thanks to the introduction of parallel streams.

Terms

Let’s review some important terms related to concurrency.

A critical section is a user-level object that ensures only one active thread within a single process can execute a particular section of code at a time. Other threads that attempt to enter this section are put to sleep until it becomes available.

A mutex, or mutual exclusion object, is managed by the operating system’s kernel. It allows only one active thread among different processes to execute a protected section. Threads that do not acquire the mutex are put to sleep.

A lock is similar to a mutex but is used within the same process. It ensures that only one active thread can proceed, while others wait.

A semaphore is a kernel object that allows a group of active threads to proceed, while others are put to sleep. Semaphores can be used for interprocess or shared actions, but they are not always safe and lack some of the properties of shared mutexes.

Monitors are special objects that combine a mutex and a conditional variable. They are synchronization constructs that control access to shared resources. Monitors provide mutual exclusion, ensuring only one thread can execute a critical section at a time, and they also allow threads to wait for specific conditions to be met. In Java, every object has an intrinsic monitor associated with it. This monitor can be used to synchronize access to the object’s methods or code blocks. It consists of intrinsic monitor locks—such as a mutex or lock—and a wait-notify mechanism for conditional synchronization.

Creation

Java provides the Thread class, the Object class, and the Runnable interface to support concurrency. The Thread class includes methods like run, start, and sleep, which are essential for multi-threading. The Object class offers methods such as wait and notify, which are specifically designed to support concurrency. Since every class in Java inherits from Object, all Java objects have basic multi-threading capabilities. Acquiring a lock on an object or instance is straightforward using the synchronized keyword.

Let’s go over some key methods related to threads in Java.

The currentThread method is a static method that returns a reference to the currently executing thread.

The getName method is an instance method that returns the name of the current thread.

The getPriority method is an instance method that returns the priority value of the current thread.

The join methods are overloaded instance methods. When one thread calls join on another, it waits until the other thread completes. You can also specify a timeout in milliseconds, or in both milliseconds and nanoseconds.

The run method is an instance method. When you start a thread using the start method, the run method is called when the thread is ready to execute.

The setName method is an instance method that changes the thread’s name to the value provided.

The setPriority method is an instance method that sets the thread’s priority to the given value.

The sleep methods are overloaded static methods. They make the current thread sleep for a specified number of milliseconds, or for a combination of milliseconds and nanoseconds.

The start method is an instance method that begins the thread’s execution. The Java Virtual Machine will then call the thread’s run method.

The toString method is an instance method that returns a string representation of the thread, including its name, priority, and group.

Creating Threads

To create thread objects in Java, you can extend the Thread class and override the run method. If you do not override the run method, the default implementation does nothing. The run method should be declared as public, take no arguments, and return void.

Here’s what the example code does:

This code defines a class called MyThread that extends the Thread class. Inside the run method, it puts the current thread to sleep for one second, then prints the current thread’s name. If the thread is interrupted during sleep, it catches and prints the exception, but otherwise ignores it, since there’s little that can be done from user space. After handling any interruption, it prints the thread’s name again.

In the main method, a new instance of MyThread is created. The start method is called to begin execution, which will eventually invoke the run method in a separate thread. Immediately after starting the new thread, the main method prints the name of the current thread, which is typically the main thread. This demonstrates that the start method is non-blocking—the main thread continues executing while the new thread runs in parallel.


There is also another way to create a thread. Instead of extending the Thread class, you can implement an anonymous class from the Runnable interface. The Thread class itself implements the Runnable interface. Runnable declares a single method called run. So, when you implement Runnable, you must provide an implementation for the run method.

The Thread class provides a constructor that accepts a Runnable argument. This allows you to create a new thread with a Runnable target.

In the following example, a class called RunnableImpl implements the Runnable interface. Inside the run method, it sleeps the current thread for one second, then prints out the current thread’s name. In the main method, a new Thread object is created using RunnableImpl as its target. The thread is started, which invokes the run method. Meanwhile, the main thread immediately prints its own name, demonstrating that the start method is non-blocking.

This example shows how to create a Thread object from a Runnable instead of extending the Thread class. This approach is generally simpler and easier to manage. It also allows threads to be more reusable and less exposed to user code.

Synchronization

Threads share memory, and they can modify data at the same time. If two or more threads try to access a variable and at least one of them wants to modify it, you can run into a problem known as a race condition, data race, or race hazard. To solve this, data modification must be done atomically—meaning only one thread can change the data at a time. This is achieved through locks and mutexes. In Java, these are called synchronized blocks.

A synchronized block locks the data being modified, ensuring that only one thread at a time can enter the modification block. Once a thread exits the block, other threads are allowed to modify the data. This protected area is called a critical section.

In Java, you can use a synchronized block to guard a section of code. The lock is obtained on a specific object instance. The lock is always released, even if an exception is thrown or the block does not complete fully. This prevents deadlocks where a lock might otherwise remain stuck, causing other threads to wait indefinitely.

You can also synchronize entire methods by placing the synchronized keyword at the front of the method declaration. In this case, when the method is called, a lock is obtained on the object instance. The lock is released when the method exits. This is similar to using a synchronized block with “this” as the lock target.

Static methods can also be declared as synchronized. In that case, the lock is obtained on the class type itself, not on an instance. In Java, the class type is treated as an object, so the lock is held on the class object.

Constructors, however, cannot be declared synchronized. This is because there is no instance to lock around during construction, and attempting to do so will produce a compiler error. You can, however, have a synchronized block inside the constructor that locks around specific data members or input arguments.

The reason you cannot declare constructors as synchronized is that the Java Virtual Machine ensures only one thread can invoke a constructor call for a specific constructor at a given time. So, there is no need to declare a constructor synchronized.

It is a common misunderstanding to think that a synchronized block obtains a lock for a block of code. In reality, the lock is obtained for an object, not for the code itself. The lock is held until all statements in the block complete execution.

Deadlocks

A deadlock arises when locking threads results in a situation where they cannot proceed and thus wait indefinitely for others to terminate. For example, imagine one thread acquires a lock on resource R1 and waits to acquire another lock on resource R2. At the same time, another thread has already acquired a lock on R2 and is waiting to obtain a lock on R1. Neither thread can proceed until the other releases its lock, which never happens. As a result, both threads are stuck in a deadlock.

In the following example, there are two classes, Balls and Runs, each with a static data member. Two Runnable implementations, CounterOne and CounterTwo, increment these variables. CounterOne locks Runs first, then Balls. CounterTwo locks Balls first, then Runs. In the main method, two threads are created and started at the same time, each running one of the counters. The program waits for both threads to finish.

This example demonstrates that, depending on which thread starts first, one may acquire the lock on Runs while the other acquires the lock on Balls. If this happens, neither thread can obtain the second lock it needs, leading to a deadlock. It is not guaranteed that this program will deadlock every time it runs, but it is possible. The sequence in which threads execute, the order in which locks are acquired and released, and the time it takes to obtain a lock all play a role in whether a deadlock occurs.

Livelocks

Now, let’s consider livelocks. Imagine two robotic cars programmed to drive automatically on a road. They both reach opposite ends of a narrow bridge that only allows one car to pass at a time. The cars are programmed to wait for the other to go first. If both cars attempt to enter the bridge at the same time, they each notice the other and reverse. They keep moving forward and backward, appearing to do a lot of work, but neither makes progress. This is called a livelock.

In the context of threads, imagine two threads, T1 and T2. Thread T1 makes a change, and thread T2 undoes that change. When both threads work, it appears as though a lot of work is being done, but no real progress is made. This situation is called a livelock in threads.


Let’s begin by considering a situation where multiple threads have different priorities assigned to them. In Java, thread priorities can range from the lowest, which is one, to the highest, which is ten. When a lock becomes available, the thread scheduler will typically give preference to threads with higher priority over those with lower priority.

However, if there are many high-priority threads that want to obtain the lock, and they also tend to hold the lock for long periods, the lower-priority threads may not get a chance to acquire the lock at all. This situation, where low-priority threads are left waiting for a long time while trying to obtain the lock, is known as lock starvation.

There are various techniques available for detecting or avoiding threading problems such as livelocks and starvation, but those are beyond the scope of this discussion.

Now, let’s talk about monitors in Java. Monitors provide a way to make the locking mechanism more flexible and allow threads to cooperate with each other. To illustrate this, consider the following example.

In this example, we have a class called SharedResource. It uses a queue to store integer values, with a fixed capacity of five. The class provides two synchronized methods: produce and consume. The produce method adds a value to the queue, but if the queue is full, it waits until space becomes available. The consume method removes a value from the queue, but if the queue is empty, it waits until there is something to consume. Both methods use wait and notifyAll to coordinate between producer and consumer threads.

In the main method, we create an instance of SharedResource. We then start a producer thread, which adds ten values to the queue, simulating a delay between each production. We also start a consumer thread, which consumes ten values from the queue, also with a delay between each consumption. Both threads are started, and the main thread waits for them to finish. Once both threads have completed, a message is printed to indicate that the producer and consumer have finished.

This example demonstrates how Java monitors, using synchronized methods along with wait and notifyAll, can be used to coordinate access to shared resources between multiple threads.

Next, let’s discuss atomics.

The java.util.concurrent package includes two important sub-packages: atomic and locks. Here, we’ll focus on atomic variables provided in the atomic package.

Often, you might need to perform simple operations like incrementing or decrementing a variable in a thread-safe way. Using locks for such primitive operations is not efficient. For these cases, Java provides atomic variables, which offer an efficient alternative.

Some of the key classes in the atomic package include:

AtomicBoolean, which allows you to atomically update a boolean value.

AtomicInteger, which allows atomic updates to an integer value and inherits from the Number class.

AtomicIntegerArray, which is an integer array where each element can be updated atomically.

AtomicLong, which allows atomic updates to a long value and also inherits from the Number class.

AtomicLongArray, which is a long array with elements that can be updated atomically.

AtomicReference, which allows atomic updates to an object reference of a specified type.

AtomicReferenceArray, which is an array that can hold object references and allows atomic updates to its elements.

It’s important to note that only AtomicInteger and AtomicLong extend from the Number class. AtomicBoolean and the other classes inherit directly from the Object class.

Of all these classes, AtomicInteger and AtomicLong are the most commonly used. Let’s go over some of their most important methods.

The default constructor, AtomicInteger, creates an instance with an initial value of zero.

You can also create an AtomicInteger with a specific initial value by passing an integer to the constructor.

The get method returns the current integer value held in the object.

The set method resets the value to a new integer.

The getAndSet method returns the current value and then sets the value to a new one.

The compareAndSet method compares the current value to an expected value, and if they are equal, sets the value to a new one. This is useful for implementing lock-free algorithms.

The getAndIncrement method returns the current value and then increments it, similar to the behavior of i plus plus for an integer.

The getAndDecrement method returns the current value and then decrements it, similar to i minus minus.

The getAndAdd method returns the current value and adds a specified delta to it.

The incrementAndGet method increments the value and then returns the new value, similar to plus plus i.

The decrementAndGet method decrements the value and returns the new value, similar to minus minus i.

The addAndGet method adds a delta to the current value and returns the new value.

Finally, there are methods to cast the current value to different types, such as intValue, longValue, floatValue, and doubleValue.

Now, let’s move on to classes and interfaces in the concurrent package.

The concurrent package provides many classes and interfaces that offer high-level APIs for concurrent programming. When you use the synchronized keyword, Java employs mutexes to synchronize access between threads, ensuring safe shared access to resources.

However, threads often need to coordinate their execution to complete larger, higher-level tasks. To facilitate this, Java provides higher-level abstractions for thread synchronization, known as synchronizers. These synchronizers are built on top of the existing low-level APIs for thread coordination, making it easier to manage complex interactions between threads.


Semaphore, CountdownLatch, Exchanger, CyclicBarrier, and Phaser

Let’s begin by introducing several important concurrency utilities in Java.

A semaphore is used to control access to a shared resource. It maintains a counter that specifies how many resources it controls. This allows you to limit the number of threads that can access a particular resource at the same time.

A countdown latch allows one or more threads to wait until a countdown is completed. This is useful when you want threads to wait for some operations to finish before proceeding.

The Exchanger class is designed for exchanging data between two threads. It is particularly useful when two threads need to synchronize with each other and continuously exchange data.

A cyclic barrier provides a synchronization point where threads can wait until all other threads reach that point. This is helpful when you need multiple threads to perform their tasks independently, but then synchronize at a certain point before moving on to the next phase.

Finally, the Phaser class is useful when several independent threads need to work in phases to complete a task.

CyclicBarrier

There are many situations in concurrent programming where threads need to wait at a predefined execution point until all other threads reach that point. The CyclicBarrier class provides such a synchronization point. In other words, it allows a set of threads to wait for each other at a common barrier point before continuing execution.

This is especially useful when you want multiple threads to perform their tasks independently, but then synchronize at a certain point before proceeding to the next phase.

When creating a CyclicBarrier, you specify the number of threads that must reach the barrier point. You can also specify an optional barrier action, which is a task executed by one of the threads when all have reached the barrier. The barrier is reusable after the threads are released, which is why it is called “cyclic.” Threads calling the await method are blocked until the required number of threads have called it.

Here’s how it works: Each thread calls the await method when it reaches the barrier. At this point, the thread can perform no more work and must wait for the other threads to finish their work. Once the required number of threads, as specified in the constructor of the CyclicBarrier, have called await, the barrier is broken and all waiting threads are released. If a barrier action is specified, it is executed by one of the threads just before the barrier is broken.

Key Methods of CyclicBarrier

The CyclicBarrier class provides several important methods.

First, the constructor CyclicBarrier, which takes the number of threads waiting on it as a parameter, creates a CyclicBarrier object. If the number of threads is negative or zero, it throws an IllegalArgumentException.

There is another constructor that takes both the number of parties and a Runnable barrier action. This allows you to specify a task to be executed when the barrier is reached.

The await method blocks until the specified number of threads have called await on this barrier. It returns the arrival index of the thread. This method can throw an InterruptedException if the thread is interrupted while waiting, or a BrokenBarrierException if the barrier was broken for some reason, such as another thread being timed out or interrupted. There is also an overloaded version of await that takes a timeout period. This version throws a TimeoutException if all other threads do not reach the barrier within the specified time.

The isBroken method returns true if the barrier is broken. A barrier is considered broken if at least one thread in that barrier was interrupted or timed out, or if a barrier action failed by throwing an exception.

Finally, the reset method resets the barrier to its initial state. If there are any threads waiting on that barrier, they will throw a BrokenBarrierException.

Example: Using CyclicBarrier for a Tennis Game

Let’s look at an example to illustrate how CyclicBarrier works.

In this example, we simulate a mixed doubles tennis game that requires four players. The game cannot start until all four players are present. The start of the game is represented by the MixedDoubleTennisGame class, which defines the action to be executed when all four threads call the await method on the CyclicBarrier object.

The Player class simulates the arrival of a player. Each player, represented by a thread, announces their readiness and then calls await on the barrier, waiting for the other players to arrive. If an exception occurs while waiting, such as a BrokenBarrierException or InterruptedException, it is caught and a message is printed.

The CyclicBarrierTest class creates a CyclicBarrier object, specifying four as the number of threads and passing an instance of MixedDoubleTennisGame as the barrier action. It then creates four Player threads, each representing a different player.

In summary, this code sets up a scenario where four player threads must all reach the barrier before the game can start. Once all four threads have called await, the run method of MixedDoubleTennisGame is executed, and the game begins.

Sample Output

The output of this program would look like the following:

First, the system announces that the tennis court is being reserved and that the game will start as soon as four players arrive.

Then, as each player thread starts, it prints a message indicating that the player is ready.

Once all four players are ready, the barrier is released, and the game starts with the message: “All four players ready, game starts. Love all…”

This demonstrates how CyclicBarrier can be used to coordinate multiple threads, ensuring that they all reach a certain point before proceeding together.


An example output from the program above might look like this. Notice that until all four players have registered—meaning the await methods have not yet been triggered—the game will not start. This simple example demonstrates how a set of threads can be interlinked, or more specifically, how their actions can be coordinated so that only when all threads have finished their work, another thread’s action can begin.

Collections

The concurrent package in Java provides several classes that are thread-safe versions of the standard collection classes found in the java util package. For example, ConcurrentHashMap is the concurrent equivalent of HashMap. The main difference between these two containers is that with HashMap, you need to explicitly synchronize insertions and deletions, whereas ConcurrentHashMap has this synchronization built in. If you are familiar with the interface of HashMap, then using ConcurrentHashMap will feel very similar.

Let’s briefly discuss some of the key concurrent collection classes and their purposes.

BlockingQueue is an interface that extends the standard Queue interface. In a BlockingQueue, if the queue is empty, any attempt to remove an element will cause the thread to wait until an element is available. Similarly, if the queue is full, any attempt to add an element will cause the thread to wait until space becomes available.

ArrayBlockingQueue provides a fixed-size, array-based implementation of the BlockingQueue interface.

LinkedBlockingQueue offers a linked-list-based implementation of BlockingQueue.

DelayQueue is a special kind of BlockingQueue where elements can only be retrieved after a certain delay period has passed.

PriorityBlockingQueue is similar to the standard PriorityQueue, but it implements the BlockingQueue interface, allowing for thread-safe, prioritized access.

SynchronousQueue is a BlockingQueue implementation where each insert operation must wait for a corresponding remove operation by another thread, and vice versa.

LinkedBlockingDeque implements a double-ended queue, or deque, where insert and remove operations can block. It uses a linked-list for its internal structure.

ConcurrentHashMap is analogous to Hashtable, but it allows for safe concurrent access and updates.

ConcurrentSkipListMap is similar to TreeMap, but it provides safe concurrent access and updates.

ConcurrentSkipListSet is the concurrent equivalent of TreeSet, again providing safe concurrent access.

CopyOnWriteArrayList is similar to ArrayList, but it is designed for safe concurrent access. When the container is modified, it creates a fresh copy of the underlying array.

CopyOnWriteArraySet is a Set implementation that provides safe concurrent access and is built using CopyOnWriteArrayList. When modified, it also creates a fresh copy of the underlying array.

CopyOnWriteArrayList

Both ArrayList and CopyOnWriteArrayList implement the List interface. There are three main differences between these two classes when used in a concurrent context.

First, ArrayList is not thread-safe, but CopyOnWriteArrayList is. This means it is unsafe to use ArrayList in situations where multiple threads are accessing or modifying the same instance, especially when modifications are being made.

Second, methods in ArrayList such as remove, add, and set can throw a ConcurrentModificationException if another thread modifies the ArrayList while it is being accessed. In contrast, it is safe to perform these operations from multiple threads on a CopyOnWriteArrayList. Methods like remove, add, and set do not throw this exception. All active iterators will still have access to the unmodified version of the container, so they remain unaffected. If you create a new iterator after a modification, it will reflect the updated container.

Third, you can obtain an iterator by calling the iterator method on a List object. If you call remove on the iterator when the underlying container has been modified, an exception can be thrown. However, with CopyOnWriteArrayList, calling remove on its iterator always throws an UnsupportedOperationException.

Let’s consider an example. The code defines a class called ModifyingList. In its main method, it creates an ArrayList of strings, adds three elements—"one", "two", and "three"—and then obtains an iterator. While iterating, it prints each element and tries to add a new element, "four", to the list during iteration.

This example demonstrates that modifying an ArrayList while iterating over it will throw a ConcurrentModificationException. In such scenarios, you might want to replace the ArrayList with a CopyOnWriteArrayList. The way CopyOnWriteArrayList works is by creating a copy of the container data whenever a new element is added. This means that if you obtain an iterator before a modification, the iterator will still point to the original, unmodified array. As a result, no exception is thrown, but the iterator will only traverse the original elements. Any new elements added after the iterator was created will not be included in the iteration.

Executors

Threads can be managed directly by creating Thread objects in your application, but this approach can be cumbersome. If you want to abstract away the low-level details of multithreaded programming, executor services are a good choice. The Executor interface declares only one method, which is execute, taking a Runnable as its argument. Derived interfaces and classes, such as ExecutorService, ThreadPoolExecutor, and ForkJoinPool, provide additional useful functionality that extends the base interface. The main idea behind the Executor hierarchy is to provide reusable containers for Thread objects, making it easier to create, destroy, reuse, and run threads.

Callable

Callable is an interface that declares a single method called call, which returns a value. It represents a task that needs to be completed by a thread, and once the task is finished, it returns a result. If the call method cannot execute or fails, it throws an Exception. To execute a task using a Callable object, you first need to create a thread pool. A thread pool is simply a collection of threads that can execute tasks.

ExecutorService

The ExecutorService interface extends the Executor interface and provides additional services, such as the ability to terminate threads and produce Future objects. Some tasks may take a significant amount of time to complete. When you submit a task to the executor service, a Future object is returned. A Future represents an object that will eventually contain the value returned by a thread. In other words, the Future is the result of an action that will be executed by a thread at some point in the future. The Future object has methods like isDone, which checks if the task is complete, and get, which can be used to obtain the result of the task. Note that the get method is blocking—if it is called before the task is done, it will block the current thread until the task completes.


Let’s walk through the concepts and examples presented in this technical explanation of Java’s concurrency utilities, focusing on Callable, ExecutorService, and the Fork/Join framework.

First, the Factorial class is introduced. This class implements the Callable interface, which allows it to be executed as a task by an ExecutorService. The purpose of this class is to compute the factorial of a given number, N, and return the result. If the input number is less than or equal to zero, the class throws an exception, indicating that the factorial is only defined for positive numbers. The core logic multiplies all numbers from one up to N to compute the factorial.

Next, the example demonstrates how Callable, Executors, ExecutorService, and Future work together. In the main method, a value N is set to twenty. A Factorial task is created for this value. Then, an ExecutorService is instantiated using a single-threaded executor. The Factorial task is submitted to the executor, and a Future object is returned. The program waits for the computation to complete by calling the get method on the Future, which blocks until the result is available. Finally, the result is printed, and the executor service is shut down.

This example highlights that Callable is used when a task needs to return a result. The Executors class provides factory methods for creating different types of executor services, such as newSingleThreadExecutor for a single thread, or newFixedThreadPool for multiple threads, depending on the desired level of parallelism. Executors are designed to manage native thread objects and provide various capabilities for task execution.

Now, let’s discuss the Fork/Join framework, which is part of the Java concurrent package. This framework simplifies writing parallelized code and is especially useful for divide-and-conquer problems. The Fork/Join framework is an implementation of the ExecutorService interface and is designed to exploit multiple processors efficiently.

The core idea is to recursively divide a large task into smaller subtasks, which can be computed independently. This process is called forking. Once the subtasks are completed, their results are combined, or joined, to produce the final result. The Fork/Join framework uses a work-stealing algorithm, where idle worker threads can steal tasks from the queues of busy threads, improving overall throughput.

The most important class in this framework is ForkJoinPool, which manages the execution and lifecycle of fork/join tasks. These tasks are instances of ForkJoinTask. The general algorithm for fork/join can be summarized as follows: fork the task, join the task, and compose the results.

The recursive approach is further detailed in the provided pseudocode. If a task is small enough, it is computed directly. Otherwise, the task is divided into two parts. The first part is computed, and the second part is joined. The results from both parts are then combined.

Within the Fork/Join framework, there are two key classes for defining tasks. RecursiveTask is used when the task returns a result, while RecursiveAction is used when no result is returned. Both classes can be run in a ForkJoinPool.

To use the Fork/Join framework effectively, first determine if the problem is suitable. The problem should be recursively divisible into independent subtasks, and the results should be combinable. If so, define a task class that extends either RecursiveTask or RecursiveAction, depending on whether a result is needed. Override the compute method to perform the task or to split it into subtasks. Subtasks can be invoked using invokeAll or fork, and their results can be obtained with join. Finally, merge the results as needed.

To execute the computation, instantiate a ForkJoinPool, create an instance of the task class, and start execution using the invoke method on the pool.

The example provided demonstrates how to compute the sum of numbers from one to one million using the Fork/Join framework. The range is divided in half recursively until each subrange is small enough to be handled by a single thread. Each thread sums its assigned range, and the results are combined to produce the final sum.

In summary, the Fork/Join framework is a powerful tool for parallelizing recursive, divide-and-conquer problems in Java. By leveraging classes like ForkJoinPool, RecursiveTask, and RecursiveAction, developers can efficiently utilize multiple processors and manage complex task lifecycles with ease.


Analyzing how this program works.

In this program, the goal is to compute the sum of all values in the range from one to one million. To make the computation efficient, the program uses ten threads to execute the tasks in parallel.

The class called RecursiveSumOfN extends RecursiveTask of type Long. Here, the long data type is used because the sum of numbers in each sub-range can be quite large. RecursiveTask is chosen instead of RecursiveAction because each subtask needs to return a value. If a subtask did not need to return a value, RecursiveAction would be more appropriate.

Within the compute method, the program decides whether to compute the sum directly or to split the task into smaller subtasks. This decision is based on the condition: if the difference between the upper and lower bounds of the range is less than or equal to the total range divided by the number of threads, then the task is small enough to be handled directly. This value acts as a threshold for splitting.

If the range is within this threshold, the sum is computed using a simple for loop over the specified range. If the range is larger, the program finds the midpoint and splits the task recursively, allowing the ForkJoin framework to process the subtasks in parallel.

At the end, the program compares the computed sum with the result from the mathematical formula for the sum of the first N natural numbers, which is N times N plus one, divided by two. It then prints both results for verification.


